[
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=8082a1f9cce68d17", "page": 21, "job_title": "Senior Data Engineer", "company_name": "OpenCredo", "job_location": "London", "job_type": "Full-time", "jobkey": "8082a1f9cce68d17", "date_posted": "5 days ago", "jobDescription": " OpenCredo (OC) is a UK based software development consultancy helping clients achieve more by leveraging modern technology and delivery approaches. We are a community of passionate technologists who thrive on delivering pragmatic solutions for our clients' most complex challenges. Curious, tenacious but always sensitive to our clients' context, we are not afraid to speak our minds to help steer our clients towards understanding and achieving their key goals. We are looking for a hands-on senior level data engineer with experience in dealing with various data centric problems and challenges. You understand the benefits of event streaming and the cases for ETL and batch processing, with experience bringing these approaches together in a coherent solution. You will have worked with modern data technologies including RDBMS as well as various NoSQL solutions, ideally operating at scale. You are excited by the prospect of data meshes and how this has the potential to change the business and data landscape. What we’re looking for: Communicable Data expert: You will be comfortable articulating and explaining key data concepts as well as diving into the details and the nitty-gritty where required. You are confident in your ability to deliver and grow as a technical Data Expert. You see value in, and make defining and documenting standard operating procedures (SOPs) and/or playbooks a part of helping ensure everyone is on the same page. Data Pipelines &amp; LifeCycle: You are comfortable designing and building scalable data pipelines, you know your ETL from your ELT and you have hands-on experience of all phases of the data lifecycle from ingestion, to cleansing, transforming as well as orchestrating the overflow. A Problem Solver with a Can Do Attitude: You can be relied on as the person who gets stuck in and makes things happen. Big Data Architectures: You have developed and worked with Big data architectures. You know what is required to support and run large-scale realtime and batch data processing workloads, including how to distribute load as appropriate. A Skilled Technologist: You have a background in programming and creating data-centric solutions using code. You are an accomplished programmer in one or more programming languages with Python being one of those. Innovation &amp; Continuous Learning: You enjoy and actively seek to learn about new technologies and techniques in the Data and AI/ML space. Requirements Experience with as many of these as possible: Real-time Streaming: Design &amp; Development of real-time data streaming solutions (including handling time series data) leveraging modern technologies and industry practises using technologies such as: Apache Kafka, Flink, Nifi, Spark, Beam Cloud Vendor Solutions: Design &amp; Development of data pipelines or solutions within one or more cloud providers (AWS, GCP, Azure) utilising a mixture of open source as well as vendor-specific data offerings. Event Driven Solutions: Hands-on architecting, design and development of event driven systems - Appropriate usage of techniques such as event sourcing, CQRS, domain driven design Data Modelling &amp; Data Engineering: A solid understanding of data modelling, including challenges handling time series data, and experience with data engineering tools and platforms such as Kafka, Spark, EMR, various RDBMS databases and Hadoop ML &amp; AI: Integration of, and productionisation of (MLOps) ML Models Handling Data At Scale: understanding or experience of one or more of : data lakehouse, data warehouse, data lake. Although aptitude and attitude are what makes a great OCer, and interviewing with OC is not a box-ticking exercise of technologies, as a rough guideline, we think you are likely to have the following on your CV: 5+ yrs of hands-on data-centric development experience Strong communication skills; ability to articulate your ideas and thoughts with others Demonstrable experience with modern data platforms, practises &amp; approaches such as Streaming, Event Sourcing, Data Pipelines Deep expertise in at least one modern data technology or solution stack Enjoy coming to work! We’re a friendly, sociable bunch who genuinely support each other and have a lot of fun Benefits In return, we’ll give you… A highly competitive basic salary 5% matched contributory pension Private Health Insurance Life Insurance 25 days’ holiday plus public holidays (plus an extra day for each year of service) Cycle to work scheme A high spec laptop (of course!) Need more reasons? Here's a few more... Work with some of the most exciting new technologies Spark off co-workers who’ll challenge your thinking and help you to achieve your potential Deal openly and honestly with customers Benefit from a transparent environment including regular company meetings where we discuss anything and everything Have exceptional opportunities as a speaker, blogger and contributor to open source projects. We have some great connections in the wider technology community that we encourage our team to make the most of! Work alongside senior leaders who understand and value passionate technologists; "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=081f950211e032c5", "page": 21, "job_title": "Lead Data Engineer", "company_name": "Enra Specialist Finance Ltd", "job_location": "Watford WD17", "job_type": "Full-time, Permanent", "jobkey": "081f950211e032c5", "date_posted": "2 days ago", "jobDescription": "Your main responsibility as a Lead Data Engineer is to take technical ownership of the Data &amp; Management Information function at Enra. Whilst working closely with the CTO &amp; the Head of Software Product to define and implement the short &amp; the long-term strategies around Data &amp; MI reports.Key Accountabilities Communicate effectively with internal customers and third parties. Analyse both large and complex reporting requirements. Collaborate effectively with Product Owners, Developers, Designers, DevOps Engineers, and the wider business. Hands-on development of MI &amp; BI reports for the various business units. Work alongside a Reporting Developer &amp; a Reporting Analyst. Support, mentor and help the more junior members of the team. Test and cross validate reports for accuracy and integrity. Perform regular, technical reviews of your team’s work. Analyse and recommend enhancements to the MI reports, processes and standards. Provide regular and ad hoc updates to the CTO.Skills &amp; Competencies Excellent data modelling skills. Experience in dashboard design and development. Experience working in a collaborative Agile environment. Mentoring skills for the less experienced members of the team. Good knowledge of SAP Business Objects would be helpful but not necessary Experience developing ETL &amp; ELT processes from multiple data sources &amp; types. Practical experience with JIRA &amp; Confluence.Knowledge &amp; Qualifications 4+ years of experience as a Data Engineer or on a similar role. Extensive experience with SQL, ideally Amazon Redshift &amp; MySQL. Extensive experience with visualisation tools, which must include Amazon QuickSight.Personal Attributes Excellent communication skills. Self-motivated and proactive Independent thinker, with a “can do” mentality. Team player. Inquisitive with a desire to learn and use new technologies.Values - CREDITCCustomer - Customers are our primary focusRResults - Results matter, create value every dayEEnergy is contagious, Share it!DDeveloping our people makes us differentIInvent the solution - be proactiveTTeamwork - Together we can build the businessJob Types: Full-time, PermanentSchedule: Monday to FridayWork Location: In person"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=21febc98a289bae8", "page": 21, "job_title": "Senior Data Engineer", "company_name": "Wiser Solutions", "job_location": "London", "job_type": "Full-time", "jobkey": "21febc98a289bae8", "date_posted": "1 day ago", "jobDescription": " Company Description Wiser Solutions is a suite of in-store and eCommerce intelligence and execution tools. We're on a mission to enable brands, retailers, and retail channel partners to gather intelligence and automate actions to optimize pricing, marketing, and operations initiatives, both in-store and online. Our Commerce Execution Suite is available globally. Job Description This is a full-time position, and hours of work are Monday through Friday, 40 hours per week. This position is remote in Poland with flexible hours, primarily working within CET time zone. We are a global company and you may be occasionally required to work outside of core working hours for meetings with different time zones. The Manager is located in the US on EST time zone. About the role: When looking to buy a product, whether it is in a brick and mortar store or online, it can be hard enough to find one that not only has the characteristics you are looking for but is also at a price that you are willing to pay. It can also be especially frustrating when you finally find one, but it is out of stock. Likewise, brands and retailers can have a difficult time getting the visibility they need to ensure you have the most seamless experience as possible in selecting their product. We at Wiser believe that shoppers should have this seamless experience, and we want to do that by providing the brands and retailers the visibility they need to make that belief a reality. Our goal is to solve a messy problem elegantly and cost effectively. Our job is to collect, categorize, and analyze lots of structured and semi-structured data from lots of different places every day (whether it’s 20 million+ products from 500+ websites or data collected from over 300,000 brick and mortar stores across the country). We help our customers be more competitive by discovering interesting patterns in this data they can use to their advantage, while being uniquely positioned to be able to do this across both online and instore. We are looking for a Senior Data Engineer to lead the charge on a team of like-minded individuals responsible for developing the data architecture that powers our data collection process and analytics platform. If you have a passion for optimization, scaling, and integration challenges, this may be the role for you. Essential Functions: Think like our customers – you will work with product and engineering leaders to define data solutions that support customers’ business practices. Be an agent for excellence – you will be collaborating with other teams to provide guidance on best practices with managing data effectively. Design/develop/extend our data pipeline services and architecture to implement your solutions – you will be collaborating on some of the most important and complex parts of our system that form the foundation for the business value our organization provides Foster team growth – provide mentorship to both junior team members and evangelizing expertise to those on others. Improve the quality of our solutions – help to build enduring trust within our organization and amongst our customers by ensuring high quality standards of the data we manage Own your work – you will take responsibility to shepherd your projects from idea through delivery into production Bring new ideas to the table – some of our best innovations originate within the team Stay abreast of new technologies and identifies ways to appropriately utilize these technologies in their product area. Assists in the curation of the Data Platform product roadmap. Technologies We Use: Languages: SQL, Python Infrastructure: AWS, Docker, Kubernetes, Apache Airflow, Apache Spark Databases: Snowflake, Redshift, MongoDB, Postgres, MySQL, EventStore Business Intelligence: Sisense, Tableau Qualifications Bachelors/Master’s degree in Computer Science or relevant technical degree 7+ years of professional software engineering experience Strong proficiency with data languages such as Python and SQL Strong proficiency working with data processing technologies such as Spark, Flink, and Airflow Strong proficiency working of RDMS/NoSQL/Big Data solutions (Postgres, MongoDB, Snowflake, etc.) Strong proficiency with building data warehouses using well known modeling practices (e.g. Slowly Changing Dimensions, Data Vault, etc.) Solid understanding of the differences between Data Lakes, Data Warehouses, and Data Marts Solid understanding of streaming solutions such as Kafka, Pulsar, Kinesis/Firehose, etc. Solid understanding of Docker and Kubernetes Solid understanding of ETL/ELT and OLTP/OLAP concepts Solid understanding of columnar/row-oriented data structures (e.g. Parquet, ORC, Avro, etc.) Proven ability to transform raw unstructured/semi-structured data into structured data in accordance with business requirements Solid understanding of AWS, Linux and infrastructure concepts Proven ability to diagnose and address data abnormalities in systems Proven ability to learn quickly, make pragmatic decisions, and adapt to changing business needs Experience building data lakes and/or leveraging data lake solutions (e.g. AWS Glue, Trino, etc.) Experience working with business intelligence solutions such as Tableau, etc. Understands Domain Driven Design concepts and accompanying Microservice Architecture Passion for data, analytics, or machine learning. Focus on value: shipping software that matters to the company and the customer Bonus Points: Experience working within a retail or ecommerce environment. Experience working with data transformation tools such as dbt, etc. Additional Information Other Duties This position may require being on call rotation to address critical production application issues outside of normal working hours. Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice. EEO STATEMENT - Wiser Solutions, Inc. is an Equal Opportunity Employer and prohibits Discrimination, Harassment, and Retaliation of any kind. Wiser Solutions, Inc. is committed to the principle of equal employment opportunity for all employees and applicants, providing a work environment free of discrimination, harassment, and retaliation. All employment decisions at Wiser Solutions, Inc. are based on business needs, job requirements, and individual qualifications, without regard to race, color, religion, sex, national origin, family or parental status, disability, genetics, age, sexual orientation, veteran status, or any other status protected by the state, federal, or local law. Wiser Solutions, Inc. will not tolerate discrimination, harassment, or retaliation based on any of these characteristics."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=c48a2471afe64fba", "page": 21, "job_title": "Graduate Data Engineer", "company_name": "Give A Grad A Go", "job_location": "London W1W", "job_type": "Full-time", "jobkey": "c48a2471afe64fba", "date_posted": "1 day ago", "jobDescription": " Flexible home working A competitive starting salary of £30,000 - £40,000, depending on experience Opportunity to work with experienced, like-minded individuals On the hunt for Data Science jobs, Data Engineering roles, or Graduate Developer jobs in London? An exciting tech company in London is seeking a Graduate Data Engineer! If you have experience in Python or other coding languages, apply to this Graduate Data Engineer role in London today! Company profile - Tech Startup In this Graduate Data Engineer role, you will be joining a dynamic tech company based in central London, their tech solution simplifies the way organisations access and share data. By providing an embedded platform that automates the technical enforcement of data policies, they help solve the large-scale challenges created by complex global data privacy regulations. They allow all different teams to come together and work collaboratively in one application. With their success, they are looking for a Data scientist to join their growing Data Science team. Job Description - Graduate Data Engineer In this Graduate Data Engineer role you'll be joining the data science team. You'll be working on projects to analyse/improve already existing models. You'll also get the chance to develop and build new tools to help improve and secure their data and develop new methods to identify sensitive data. If you're looking to start your career in Data Science this is the role for you. Key responsibilities - Graduate Data Engineer In this Graduate Data Engineer job in London, your responsibilities will include: Develop new methods to identify sensitive data using NLP Work on projects to analyse and improve existing models Develop and build new tools to help people secure their data Work as part of the broader data-science / developer team to develop data masking solutions Job requirements - Graduate Data Engineer Degree in Computer Science, Maths, Physics, Engineering or similar Ideally educated to Masters or PhD level Experience in C++, Java or Python Desire to constantly learn new tools and languages A passion for data science and turning concepts into products Comfortable working individually and as a team Great communication, both written and verbal Benefits of the job - Graduate Data Engineer A competitive starting salary of £30,000 - £40,000, depending on experience Opportunity to work with experienced, like-minded individuals Laptop/tech provided Flexible home working Regular meetup The chance to join an exciting company in a period of significant growth Looking for Graduate Data Science jobs and Developer jobs in London? If you're a highly technical graduate with previous experience in data models and data engineering, apply to this Graduate Data Engineer role in London today! Give A Grad a Go is committed to being an equal opportunity employer. All qualified applicants will receive consideration regardless of race, religion, sexual orientation, gender, age, disability, or other. We are continually finding ways to improve the way we work, read our Diversity and Inclusion promise for more information about this."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=dcdafdf8f986d156", "page": 21, "job_title": "Cloud Data Engineer- Senior", "company_name": "Gentrack", "job_location": "London NW1", "job_type": null, "jobkey": "dcdafdf8f986d156", "date_posted": "3 days ago", "jobDescription": " The Company The global pace of change is accelerating, and utilities need to rebuild for a more sustainable future. Gentrack provides utilities across the world with market leading products and services to drive their transformation. Working with some of the world’s biggest energy and water companies, as well as innovative challenger brands, we’re helping companies reshape what it means to be a utilities business. We are driven by our passion to create positive impact. That is why utilities rely on us to manage complexity, deliver exceptional customer experiences, and secure profits. Together, we are renewing utilities. Our Values and Culture Colleagues at Gentrack are one close team of passionate people who want to drive change through technology and believe in making a difference. Our values drive decisions and how we interact and communicate with customers, partners and each other. Our core values are: Respect for the planet Respect for our customers Respect for each other Gentrackers are a group of smart thinkers and dedicated doers, outside of work we are musicians, travel fanatics, artists, sailors, family folk, environmentalists and sport lovers. We are a diverse team who love our work and the people we work with and who collaborate and inspire each other to deliver creative solutions that make our customers successful. This is a truly exciting time to join Gentrack with a clear growth strategy and a world class leadership team working to fulfil Gentrack’s global aspirations by having the most talented people, an inspiring culture, and a people-centric business. We are looking for an enthusiastic Cloud Data Engineer to join our mission to make the World cleaner and greener and become an integral part of our top notch Data Engineering team About you: You are an expert data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. You have 5+ years commercial data engineering experience with track record of successful deliverables You are proficient at SQL language as well as ETL/ELT tools and frameworks You have experience working with Snowflake (ideally) or other cloud-based data warehousing platform (e.g. Amazon Redshift, Google BigQuery, etc) You have experience with public cloud infrastructure, ideally AWS Nice to have experience: Data visualisation through Tableau (ideally) / Power BI or another similar platform Python #LI-KC1"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=e6f806a2c25d9ef4", "page": 21, "job_title": "Data Engineer", "company_name": "Urban Empire Recruitment", "job_location": "London", "job_type": "Full-time", "jobkey": "e6f806a2c25d9ef4", "date_posted": "4 days ago", "jobDescription": " Job Title: Junior Data Engineer Salary: £35,000 - £41,000 (plus 10% performance related bonus) Location: London (3 days in the office) Job Type: Full Time, PermanentUrban Empire recruitment has partnered with a healthcare provider that’s putting data at the heart of everything they do. We’re looking for 3 Data Engineer’s that like solving complex problems. You will help us to create and develop data as we move forward into our new Snowflake environment to ensure we deliver accurate and timely information to the rest of the business.You’ll report to the Head of Data &amp; Analytics, Chief Information Officer and work in a cohesive data team consisting of 3 data engineers, 2 BI developers, Data Analysts, and a data manager.Responsibilities: Develop and implement data pipelines that extract, transform and load data using into our Snowflake environment for use with reporting tools such as Power BI and SSRS. Work on ingesting, storing, processing, and analysing large data sets. Assist in the creation and maintenance of a scalable and high-performance data warehouse. Translate complex technical and functional requirements into detailed designs. Investigate and analyse alternative solutions to data storing, processing etc. to ensure the most streamlined approaches are implemented. Take responsibility for data set development and implementation. Help define data governance policies and support data versioning processes. Define, build, and maintain the data pipelines that will enable faster, better, data-informed decision-making within the business. An expert in SQL development, designing and developing scalable ETL packages from the business source systems. Analyse complex data elements and systems, data flow, dependencies, and relationships to contribute to conceptual physical and logical data models. Responsible for designing, architecting, and developing the data environment. Supporting and influencing the implementation of the data strategy. Work collaboratively with the entire Data &amp; Analytics teams, providing support to the entire department for its data centric needs. Keep up with industry trends and best practices, advising senior management on new and improved data engineering strategies that will drive departmental performance, promoting informed decision-making, and ultimately improving overall business performance. The ability to discuss technical messages to Technical and non-technical colleagues. Documentation of Data architecture, policies, and procedures.Knowledge and experience have 1 yrs experience in a data engineering role Experience in Data Warehouse Development and methodologies. Experience in Data Development. Experience in Data Modelling. Good knowledge of non-structured database solutions. Experience with Git/GitHub or other version control tool. Experience with DevOps or similar. Experience with data structures, modelling and algorithms, Azure Date Lake, Manage data and Metadata, CI/CD Deployment. Database systems (SQL), ETL tools, Data API’s, Multiple programming languages (Java, Python, C/C#) Experience working with cloud computing (Azure, AWS, GCP, we use Azure) infrastructure and data platforms. Knowledge of industry wide analytical and visualisation tools. Strong Data Engineering Skills. Experience with modern data engineering tools such as Azure Data Factory, Databricks, Apache Spark and Git;A good understanding of alternative software engineering life cycle approaches for development and the concepts and practices required to implement effective information systems.When you apply for this role a consultant from Urban Empire Recruitment will give you a call if you’re application is successful.Please note due to the large volume of applications we receive for these roles, if we have not contacted you within 7 days then unfortunately your application hasn't been successful. however, we may contact you regarding other roles. We're sorry we can't contact you directly, but we wish you all the best in your job search.Job Type: Full-timeSalary: £35,000.00-£45,000.00 per yearBenefits: Company pension Flexitime Gym membership Work from homeSchedule: Flexitime Monday to FridayAbility to commute/relocate: London: reliably commute or plan to relocate before starting work (required)Work authorisation: United Kingdom (required)Work Location: In person"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=f215f6b0804f9248", "page": 21, "job_title": "Junior Data Engineer", "company_name": "Give A Grad A Go", "job_location": "London W1W", "job_type": "Full-time", "jobkey": "f215f6b0804f9248", "date_posted": "1 day ago", "jobDescription": " Flexible home working A competitive starting salary of £30,000 - £40,000, depending on experience Opportunity to work with experienced, like-minded individuals On the hunt for Data Science jobs, Data Engineering roles, or Graduate Developer jobs in London? An exciting tech company in London is seeking a Junior Data Engineer! If you have experience in Python or other coding languages, apply to this Junior Data Engineer role in London today! Company profile - Tech Startup In this Junior Data Engineer role, you will be joining a dynamic tech company based in central London, their tech solution simplifies the way organisations access and share data. By providing an embedded platform that automates the technical enforcement of data policies, they help solve the large-scale challenges created by complex global data privacy regulations. They allow all different teams to come together and work collaboratively in one application. With their success, they are looking for a Data scientist to join their growing Data Science team. Job Description - Junior Data Engineer In this Junior Data Engineer role you'll be joining the data science team. You'll be working on projects to analyse/improve already existing models. You'll also get the chance to develop and build new tools to help improve and secure their data and develop new methods to identify sensitive data. If you're looking to start your career in Data Science this is the role for you. Key responsibilities - Junior Data Engineer In this Junior Data Engineer job in London, your responsibilities will include: Develop new methods to identify sensitive data using NLP Work on projects to analyse and improve existing models Develop and build new tools to help people secure their data Work as part of the broader data-science / developer team to develop data masking solutions Job requirements - Junior Data Engineer Degree in Computer Science, Maths, Physics, Engineering or similar Ideally educated to Masters or PhD level Experience in C++, Java or Python Desire to constantly learn new tools and languages A passion for data science and turning concepts into products Comfortable working individually and as a team Great communication, both written and verbal Benefits of the job - Junior Data Engineer A competitive starting salary of £30,000 - £40,000, depending on experience Opportunity to work with experienced, like-minded individuals Laptop/tech provided Flexible home working Regular meetup The chance to join an exciting company in a period of significant growth Looking for Graduate Data Science jobs and Developer jobs in London? If you're a highly technical graduate with previous experience in data models and data engineering, apply to this Junior Data Engineer role in London today! Give A Grad a Go is committed to being an equal opportunity employer. All qualified applicants will receive consideration regardless of race, religion, sexual orientation, gender, age, disability, or other. We are continually finding ways to improve the way we work, read our Diversity and Inclusion promise for more information about this."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=56ea971c00be9499", "page": 21, "job_title": "Senior Data Engineer", "company_name": "Pirical", "job_location": "London N1", "job_type": "Full-time, Permanent", "jobkey": "56ea971c00be9499", "date_posted": "6 days ago", "jobDescription": "Pirical is pioneering the field of People Analytics. We are on a mission to help companies make fairer and better decisions about their people by helping our customers answer tough people strategy questions like: 'How can we achieve 30% of women in leadership by 2030?' or 'How can we eliminate bias in the recruitment process?’. This is enabled by our innovative knowledge management systems and data automation techniques.We are an organically grown business that already has some of the world’s leading law firms as our clients both here in the UK and in the US, and we have ambitious plans to grow our business even further.We are looking to hire a Data Engineering Lead to join the team developing our flagship product: POD. This role is perfect for someone who is driven by impact and wants to work in a mission driven environment.The team…As a Senior Data Engineer you will be part of our Customer Success team and work on our unique, award-winning people analytics platform, Pirical On Demand. The Customer Success team consists of 10+ strong and ambitious team members either data engineers or implementation managers. The team has an informal, hard-working, and supportive team culture which allows us to deliver the best results!Pirical On Demand is a growing product built on cutting edge data engineering technologies and supported by efficient and scalable data pipelines. As a Data Engineering Lead you will design and build low fault, high performance data pipelines for the POD product - as well as contribute to the development of Junior members of the team through coaching, mentoring, and setting high Engineering standards.The role... Assume stewardship of all client data pipelines and associated infrastructure Make design decisions to solve complex client data processing problems Design and build low fault high performance data pipelines for the POD product Set high engineering standards for the team Mentor junior data engineers Interact with clients to collect the right data and to gain in-depth understanding of what the data represents This is a hybrid role that will require some time spent in the officeThe person... You will have roughly 5 years of experience working in data engineering, and understand the value it can bring if effectively handled and transformed You will have extensive experience in Python and AWS You will have good foundational knowledge on software engineering and software performance Experience developing others would be beneficial but is not essential You have a good eye for detail and feel satisfied when things are tidy and organised You are a team player and want to work in a great team to achieve results of high standards You are passionate about improving processes and delivering good service to othersTechnologies we use: AWS services (S3, SageMaker, Cloud9, Redshift, Neptune, Glue (starting 2023), Redshift Spectrum (starting 2023), and more…) Jupyter Notebooks Great Expectations, Prefect (starting 2023) Custom In-house tools (processing factories, CLIs, pipeline orchestration apps) Graph databases, Semantic web standards, Ontologies and knowledge representationThe benefits... Our work is meaningful and we have laser focus on customer impact. You'll see your work make a difference for someone else. Private health insurance 25 Days Holiday and unlimited after 2 years of employment! Team Events (eg. Book Club, Clash of Code, Team Yoga, ...) Personal Development Opportunities (eg. training, 1:1 mentoring, ...)Pirical is committed to being an inclusive and diverse place to work. The excellent work produced at Pirical would not be possible without bringing together all of the different backgrounds, experiences and skills that our team has. We treat every employee equally, and fairly regardless of age, disability, gender, marital status, race, religion, or sexual orientation. It is vitally important that each of our team members feels confident, comfortable, and empowered.Note to recruitment agencies: Pirical is committed to building a long-term approach to our hiring strategy, we are therefore already working in partnership with selected talent partners. We, therefore, ask you to hold off sending speculative CVs or sales approaches through this email.Job Types: Full-time, PermanentSalary: £80,000.00-£100,000.00 per yearBenefits: Casual dress Company pension Work from homeSchedule: Monday to FridayExperience: Data Engineering: 5 years (required)Work authorisation: United Kingdom (required)Work Location: Hybrid remote in London, N1 7GU"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=2fba2a7e386968b4", "page": 21, "job_title": "Senior Data Engineer", "company_name": "Pazikas Group", "job_location": "London", "job_type": "Full-time, Permanent", "jobkey": "2fba2a7e386968b4", "date_posted": "6 days ago", "jobDescription": "My consultancy client is looking for a Senior Data Engineer to join them. Role can be WFH and on client-site when required. With a presence on five continents and more than 4,500 employees, innovation is at the heart of their development and they are involved in areas linked to the technological changes of major groups, such as Big Data, IoT, Blockchain and Artificial Intelligence.Candidates should have (as a minimum): Strong experience designing and delivering data solutions in Microsoft Azure, Microsoft Power BI and Databricks Minimum 5 years’ experience as a Data Engineer with previous experience in industry Project leadership skills, and experience in managing projects You must have recent or current experience working within Financial Services onshore in UK, in particular Retail Banking would be a great benefitThese roles do not provide SPONSORSHIPJob Types: Full-time, PermanentSalary: £60,000.00-£75,000.00 per yearBenefits: Additional leave Company events Company pension Gym membership Life insurance Private medical insuranceSchedule: Monday to FridayExperience: Data Engineering: 5 years (required)Work authorisation: United Kingdom (required)Work Location: Hybrid remote in LondonReference ID: BDM"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=582b594213645d92", "page": 21, "job_title": "Data Engineer - London", "company_name": "InterWorks, Inc.", "job_location": "London", "job_type": "Full-time", "jobkey": "582b594213645d92", "date_posted": "Today", "jobDescription": " We know that there are all kinds of data engineers, with varying levels of knowledge about different platforms and data sources. At InterWorks, we’re more interested in candidates who are hard-working, smart and love what they do. We care more about overall data and programming skills rather than experience with a certain database platform. Whether you have worked primarily in SQL Server, Postgres or something else, we only ask that you have a strong understanding of building data pipelines and can apply your skills within our fast paced and agile approach. While some companies may hide their data engineers away in some dungeon, data engineers at InterWorks are social, friendly creatures. That is why being able to communicate with clients day in and day out is especially valuable. Our data engineers must be able to work closely with users in order to understand their needs and help them as best as possible. You might find it difficult to do the same thing each day at InterWorks. Data Engineers can expect to work on diverse projects ranging from a few days to several months. Many of these projects include solving data acquisition, integration and management problems for some of the largest organizations in the world. Projects also include working with disparate data sources (Relational databases, flat files, Excel, HDFS/Big Data systems, high performance analytical databases, etc.) to unify client data, creating ETL processes based on client needs and managing client expectations. InterWorks prides itself on having an exciting work environment, with a unique company culture. InterWorks employees are some of the most intelligent and friendly people you will ever meet, and they are the primary reason for the success of InterWorks. Joining the InterWorks team as a Data Engineer means joining a family and our family is growing faster than ever. Skills and Requirements Here are some basic requirements that we look for in our Data engineers: Required: Excellent SQL skills Programming ability (Python, Java, C#, PHP, etc.) Strong ETL skills using GUI based tools or code based patterns Understanding of data modeling principles Excellent verbal and written communication skills Business acumen Strong problem solving skills Easily adaptable and flexible to changing situations Passion for delivering compelling solutions that exceed client expectations Highly Desired: Experience with software engineering practices Experience with modern data engineering practices and frameworks Experience with integration from API sources About InterWorks InterWorks Europe is a business-to-business IT consulting firm with offices in London, Dusseldorf, and Zurich as well as staff across Europe, the US, Australia and Singapore. InterWorks opened its doors in 1996 to focus on I.T. networking with an emphasis on customer service. Still focusing on the needs of the customer, we now serve clients by offering network architecture, software development, web strategy and business intelligence services on a national and global scale. About the Business Intelligence Team At InterWorks, we’re on the front lines of the big data revolution. Companies around the world continue to seek us out to meet their big data needs. That is why InterWorks assembled the best and brightest business intelligence team there ever was, wielding powerful data tools like Tableau and Exasol. Our BI team provides solutions to some of the largest organisations in the world, including several Fortune 500 companies, government organisations, and respected universities. Click here for the InterWorks Privacy Policy sCMNXKmaQL"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=6b1589e04d77f734", "page": 21, "job_title": "Azure Data Engineer", "company_name": "Athsai Consultants", "job_location": "London", "job_type": "Full-time, Permanent", "jobkey": "6b1589e04d77f734", "date_posted": "Today", "jobDescription": "Experience working with Azure Services like Azure Data Factory, Logic App, Functions, Azure SQL DB, Blob Storage, Azure DevOps.· Experience working with other Azure Services like Azure Database Migration Service, ADLS Gen2, Synapse Analytics is an added advantage.· Experience creating Azure Data Factory pipelines leveraging Data Movement activities, Data Transformation activities like Data Flow, Stored Procedure, Custom Activity, Azure Functions etc. and Control Flow Activities like web activity, lookup activity etc.· Deploy, schedule, and monitor pipelines using Azure Data Factory.· Identify optimal data ingestion methods and develop batch processing solutions using Azure Data Factory.· Design, Develop, Migration, Integration and configuring an Azure infrastructure.· Determining workloads requirements for Azure cloud· Running workloads securely on Azure· Implementing Azure authentication and securing data on the cloud· Designing a business continuity strategy· Experience working with RDBMS preferably Azure SQL, Microsoft SQL Server.· Proficient in SQL, Transact-SQL and experience in developing Stored procedures.· Experience in any programming language, preferably C#, Python.· Expert level knowledge and usage of Azure Web Apps, Application Insights and Azure Active Directory· Must have expert level knowledge of Key Vault for application security for data in transit and rest.· Implementing Azure authentication and securing data on the cloud using Key Vaults and Azure AD· Good knowledge of Agile, DevOps delivery methodologies.Job Types: Full-time, PermanentSalary: Up to £4,700.00 per monthBenefits: Company events Company pension Gym membershipSchedule: Monday to FridaySupplemental pay types: Performance bonusExperience: Azure Devops (required) ADF (required) SQL (required) C# (required) Python (required)Work authorisation: United Kingdom (required)Work Location: One locationReference ID: Hemant@athsai.co.uk"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=1eb169af7ab4efaa", "page": 21, "job_title": "Principal Data Engineer", "company_name": "Harnham", "job_location": "London", "job_type": "Permanent", "jobkey": "1eb169af7ab4efaa", "date_posted": "3 days ago", "jobDescription": " INFO SALARY: £75000 - £95000 LOCATION London JOB TYPE Permanent PRINCIPAL DATA ENGINEER UP TO £95,000 + BENEFITS LONDON, CURRENTLY HYBRID WORKING Harnham has partnered with a global investment company helping millions of customers across the world maximise their savings and grow their capital. They are looking for a Principal Data Engineer to help scale up their data team. THE COMPANY: This is an access management company, and with a new modern data-driven team it is a very exciting time to join the company. While it is a very established banking company, they have invested heavily into creating a modern team with an up-to-date tech stack. This company offers benefits that come with being a well-established company alongside joining a fast-growing modern team with lots of potential for career progression. THE ROLE: Working cross-functionally with the marketing and data science team to expand the company's business. Build, automate and maintain ETL pipelines using Scala and Python. Mentor the junior data engineers within the team. Working with a creative mindset to solve problems and develop current production. Work with solution architects to ensure standards are upheld within the company. YOUR SKILLS &amp; EXPERIENCES Highly proficient in Python programming A good understanding of cloud architecture such as AWS or Azure. Experience in Spark Good coding practice using tools such as CI/CD. Experience in using Airflow. HOW TO APPLY: Please register your interest by sending your CV to Joy Bruty via the apply link on this page. (The company has outlined a fully remote interview process and has a remote onboarding policy in place). CONTACT Joy Bruty Recruitment Consultant "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=2d7b3c29a208c09b", "page": 21, "job_title": "DBA / Data Engineer", "company_name": "Opus Recruitment Solutions", "job_location": "Brentwood", "job_type": "Permanent", "jobkey": "2d7b3c29a208c09b", "date_posted": "6 days ago", "jobDescription": " Database Administrator / Data Engineer | Brentwood | £45,000 - £55,000 | Flexible and Hybrid Data | MSSQL | MS Dynamics | Order Wyse | Data Warehouses | Postgres Robotics | ETL | OLTp | OLAP | PowerBI | Powerapps and more An opportunity has arisen for you, a talented Data Management Specialist to join a dynamic IT team. The Data Management Specialist will be responsible for ensuring the smooth functioning and optimal performance of the company's databases. Collaborating closely with the IT team, they will implement best practices, drive data security measures, and promote efficient data management processes. The ideal candidate will have a strong passion for data and a desire to contribute to the success of the organization. This role has massive scope for progression, this will be the first dedicated Data role within the business, a role that has so far been undertaken by the IT Manager, you’ll have huge influence on which technologies to use and implement. Quoted from the hiring manager, you’ll be the “King or Queen of Data”, and will be the person to implement both procedural and technical change. This companies’ data function is in its infancy, but over time your role with grow into a Head of Data position with the opportunity to make it your own. You’ll oversee this businesses warehouse of Robots which is unbelievably cool too. What you’ll do - Oversee the performance and uptime of the company's databases, ensuring seamless operations. Collaborate with the IT team to implement effective data management practices and processes. Identify areas for improvement and propose innovative solutions to enhance database functionality. Maintain data security and ensure compliance with relevant regulations. Develop and maintain documentation of database systems and processes. Participate in data analysis and provide insights to support business decision-making. Collaborate with stakeholders to understand their data needs and provide efficient solutions. Monitor database performance and troubleshoot issues as they arise. Stay updated on industry trends and emerging technologies related to data management. Support the IT team in data-related projects and initiatives. And what they’re after – The ideal candidate will have proven experience in data management, database administration, or a related role. Strong knowledge of database systems and technologies is required. Experience with data security and compliance regulations is preferred. Proficiency in data analysis and reporting is highly desirable. Familiarity with database performance optimization techniques is a plus. Strong problem-solving and troubleshooting skills are essential. Excellent communication and collaboration abilities are required. This role is an excellent opportunity for a Data Engineer / Administrator who has already a few years’ experience under their belt. You’ll join a team doing interesting work in an interesting industry. And in return – A salary up to £55,000 Flexible and remote working (3 days pw in office) Bonus And more This role is a hybrid role in Brentwood, for that reason, you need to be based in the area with full right to work in the UK. Fully remote working is not available. If you are interested, apply now to be considered. Database Administrator / Data Engineer | Brentwood | £45,000 - £55,000 | Flexible and Hybrid Data | MSSQL | MS Dynamics | Order Wyse | Data Warehouses | Postgres Robotics | ETL | OLTp | OLAP | PowerBI | Powerapps and more"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=aa6842242b8cbfab", "page": 19, "job_title": "Senior Data Engineer Manager", "company_name": "Harnham", "job_location": "London", "job_type": "Permanent", "jobkey": "aa6842242b8cbfab", "date_posted": "1 day ago", "jobDescription": " INFO SALARY: £100000 - £110000 LOCATION London JOB TYPE Permanent Job Advertisement: Senior Data Engineering Manager Location: London Work from Home: 1 Day a week in the office. Salary: Up to £110,000 plus an up to 30% bonus A leading airline company is seeking a highly skilled and experienced Senior Data Engineer/Tech Manager to join their dynamic team based in London. As the Senior Data Engineering Manager, you will play a pivotal role in driving the organization's DataOps culture and leading teams of talented data engineers. The role: The Senior Data Engineering Manager will have 6 direct reports who are all managers with their respective teams. You will report directly to the Head of Data &amp; Technology, who reports into the Tech Director. The hiring manager is a highly experienced leader who will provide guidance and support to help you excel in your role. The Senior Data Engineering Manager will be heavily involved in resource and people management within the organisation. The company: The company is committed to providing a stimulating and rewarding work environment. They value their employees and believe in fostering a culture of diversity and inclusivity. With several years of service and growth opportunities within the company, this role offers great potential for career advancement. Who are they looking for: The ideal candidate will come from a Data Engineering background, ideally using Python, AWS and Databricks. Most importantly the right candidate will have strong experience managing multiple teams within an organisation as well as having strong communication skills. The interview process: The interview process will consist of multiple stages, including an initial interview with the hiring manager to assess your ability to establish and drive DataOps culture. The process may also involve meetings with other key stakeholders to discuss culture fit and career progression opportunities. How to apply: Please register your interest by sending your CV to Ewan Heyworth via the apply link on this page. CONTACT Ewan Heyworth Recruitment Consultant "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=c1338aed4f80fcfe", "page": 3, "job_title": "Senior Data Engineer", "company_name": "Proactive IT", "job_location": "Redhill", "job_type": "Permanent", "jobkey": "c1338aed4f80fcfe", "date_posted": "5 days ago", "jobDescription": "9563BRM16 £60k – 65k per year Senior Data Engineer – Redhill – Perm £60,000 -£65,000 p/a 3 Days a week on site Our client is urgently looking for a Senior Data Engineer to join their team based in Redhill on a permanent basis. The Data Engineer designs and implements data flows/data sets to connect operational systems data for business intelligence and analytics that are easy to use. They will be key in the delivery of solutions for predictive analytics, using innovative ways to connect multiple data sources to draw insights from data. You will be rewarded with an excellent salary and a brilliant benefit package including, annual leave, pension scheme, healthcare, flexible/hybrid working, and many more perks! Senior Data Engineer – Redhill – Perm Key Skills: At least 1 year in Azure experience Good understanding of Dimensional Modelling Azure Data tech stack database design, relational and dimensional modelling Delivery of ETL and Data solutions in cloud-based infrastructure. Knowledge of Data and Visualisation tools, primarily Power BI Must have a valid Visa and client cannot provide Sponsorship. Senior Data Engineer – Redhill – Perm Due to the volume of applications received for positions, it will not be possible to respond to all applications and only applicants who are considered suitable for interview will be contacted. Proactive Appointments Limited operates as an employment agency and employment business and is an equal opportunities organisation We take our obligations to protect your personal data very seriously. Any information provided to us will be processed as detailed in our Privacy Notice, a copy of which can be found on our website http://proactive.it/privacy-notice/"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=5c585869fc5c5837", "page": 2, "job_title": "Senior Data Engineer", "company_name": "GSK", "job_location": "London", "job_type": null, "jobkey": "5c585869fc5c5837", "date_posted": "5 days ago", "jobDescription": " Site Name: USA - California - San Francisco, Cambridge 300 Technology Square, London The Stanley Building, USA - Washington - Seattle Posted Date: Jun 16 2023 This role can be office based within the greater Seattle, WA location. The specific location of the Seattle office will be determined in the near future. The Onyx Research Data Platform organization represents a major investment by GSK R&amp;D and Digital &amp; Tech, designed to deliver a step-change in our ability to leverage data, knowledge, and prediction to find new medicines. We are a full-stack shop consisting of product and portfolio leadership, data engineering, infrastructure and DevOps, data / metadata / knowledge platforms, and AI/ML and analysis platforms, all geared toward: Building a next-generation data experience for GSK’s scientists, engineers, and decision-makers, increasing productivity and reducing time spent on “data mechanics” Providing best-in-class AI/ML and data analysis environments to accelerate our predictive capabilities and attract top-tier talent Aggressively engineering our data at scale to unlock the value of our combined data assets and predictions in real-time The Knowledge Graph Platform Engineering team is responsible for the design, delivery, and maintenance of a world-class, scalable, and industrialized Knowledge Graph platform. They deliver a petabyte scale Knowledge Graph into production that is resilient, available, and most importantly scalable. They support and maintain the operations of the Knowledge Graph using a site reliability approach through monitoring, auditing, and alerting to intercept potential issues before they reach the analysis and end users. They deliver the infrastructure, IAC, and microservices used by application teams to create subgraphs that power artificial intelligence and analysis with the goal of accelerating drug discovery. They deliver the event driven microservices to bridge the gap between end user subgraph queries, data management, ontology management, and data governance systems. This role is responsible for architecting, building, and maintaining a world-beating Knowledge Graph Platform. The Senior Knowledge Graph Engineer is a leading technical contributor who can consistently design, scope, and deliver data projects. They should be deeply familiar with the languages and tools of modern data engineering (e.g., Scala, Spark, Kafka, ...), and engaged with the open-source community surrounding them. They support the Director of Knowledge Graph Platform Engineering in building a strong culture of accountability and ownership, as well as model best-in-class engineering practices (e.g., testing, code reviews, documentation, and DevOps-forward ways of working). They work in harmony with teammates and in close partnership with Product, Platform, and user groups such as AI/ML engineers to ensure the right data orchestration and robustness of our services. Key responsibilities for the Sr. Data Engineer include: Designs, builds, and operates data tools, services, workflows, etc on petabytes of data on Cloud by leveraging modern data engineering tools and orchestration tools. Measure, optimize, and architect high performance systems, especially, evaluate and optimize Knowledge Graph data storage and query performance. Resolve customer-facing issues and fix bugs. Debug and resolve complex issues related to knowledge graph construction and management in a timely manner. Stay up-to-date with emerging trends and technologies in knowledge graph and streaming data processing. Collaborate with cross-functional teams (product, platform, Quality, and DevOps) to translate business problems into technical solutions that leverage the knowledge graph. Fully versed in coding best practices and ways of working, participates in code reviews and provide constructive feedback to improve code quality and team’s standards. Design, debug, and scale core query language engine. Deploy to GCP using CI/CD best practices, monitor and manage GCP resources. Develop secure, auditable, and performant graph query services for consumers such as AI/ML and other research teams, and integrate the query services into data catalogue, governance, and security services. Why you? Basic Qualifications: We are looking for professionals with these required skills to achieve our goals: Bachelor’s degree in computer science, Software Engineering or related discipline. Cloud experience e.g., AWS, Google Cloud, Azure, Kubernetes Must have experience with Spark or Scala Preferred Qualifications: If you have the following characteristics, it would be a plus: Masters or PHD in CS, Software Engineering or related discipline. Deep experience with industry standard big data technologies e.g., Spark, BigQuery, Kafka, HDFS, Delta Lake. Deep experience using Scala, including toolchain, documentation, testing, and operations / observability. Strong functional programming background. Experience with parser combinators, relational algebra. Experience with linked data, especially RDF. Experience with various data storage solutions (SQL, key-value, column, document, graph stores). Experience with data modelling, particularly involving the use of semantic data and ontologies/taxonomies/business data. Deep experience utilizing infrastructure as code technologies to produce repeatable architectures e.g., Terraform, Cloud templates Experience delivering microservices utilizing an event driven architecture Application experience of CI/CD implementations using git and a common CI/CD stack: e.g., Jenkins, CircleCI, GitLab, Azure DevOps Experience in modern software development tools / ways of working: e.g., git/GitHub, DevOps tools, metrics / monitoring Why GSK? Our values and expectations are at the heart of everything we do and form an important part of our culture. These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities: Agile and distributed decision-making – using evidence and applying judgement to balance pace, rigour and risk Managing individual and team performance. Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution. Implementing change initiatives and leading change. Sustaining energy and well-being, building resilience in teams. Continuously looking for opportunities to learn, build skills and share learning both internally and externally. Developing people and building a talent pipeline. Translating strategy into action - a compelling narrative, motivating others, setting objectives and delegation. Building strong relationships and collaboration, managing trusted stakeholder relationships internally and externally. Budgeting and forecasting, commercial and financial acumen. #LI-GSK #GSKOnyx GSK offers a competitive compensation package inclusive of the following: Competitive base salary, annual bonus based on company performance, access to healthcare and wellbeing programs, retirement savings program, paid time off, and employee recognition programs which reward exceptional achievements. The salary range for this role is: $145,877 to $197,363GSK offers a competitive compensation package inclusive of the following: Competitive base salary, annual bonus based on company performance, access to healthcare and wellbeing programs, retirement savings program, paid time off, and employee recognition programs which reward exceptional achievements. The salary range for this role is: $145,877 to $197,363 GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organisation where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030. Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce. If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US). GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class. Important notice to Employment businesses/ Agencies GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site. Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK’s compliance to all federal and state US Transparency requirements. For more information, please visit GSK’s Transparency Reporting For the Record site."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=7796f79faf724ee7", "page": 2, "job_title": "Quantexa Data Engineer", "company_name": "Lorien", "job_location": "London", "job_type": "Permanent", "jobkey": "7796f79faf724ee7", "date_posted": "2 days ago", "jobDescription": " Quantexa Data Engineer Base Salary + 20% benefit Package -10% pension -Private medical care -10% Cash benefit Responsibilities: Design, develop, and maintain large-scale data pipelines using Quantexa and Scala Work with data scientists to develop and deploy machine learning models Work with business users to understand their data needs and develop solutions Stay up-to-date on the latest trends in data engineering and machine learning Qualifications: Bachelor's degree in computer science, data science, or a related field Certified in Quantexa 3+ years of experience with Quantexa and Scala Experience with machine learning and artificial intelligence Experience with data warehousing and data lakes Excellent problem-solving and analytical skills Strong communication and teamwork skills We are an equal opportunities employer and welcome applications from all suitably qualified persons regardless of their race, sex, disability, religion/belief, sexual orientation, gender reassignment, marriage and civil partnerships, pregnancy or maternity or age"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=f111a5d1f2f7095c", "page": 2, "job_title": "Lead Data Engineer", "company_name": "Metrica Recruitment", "job_location": "London", "job_type": "Full-time", "jobkey": "f111a5d1f2f7095c", "date_posted": "6 days ago", "jobDescription": " Join an exciting journey with a growing Fin-Tech start-up that is seeking a talented Lead Data Engineer to drive their data infrastructure. This role offers an exceptional opportunity to be part of a visionary organisation committed to setting new industry standards. By leveraging the power of data and implementing robust technical solutions, they aim to differentiate themselves in remarkable ways. Professional development is highly valued, with engaging projects that attract and retain top talent. Be part of a team dedicated to revolutionising data interpretation using cutting-edge technology. Together, we will reshape the future. Responsibilities: As a Lead Data Engineer, you will play a pivotal role in designing, developing, and maintaining the company's data infrastructure. You will provide technical guidance and mentorship to a team of skilled data engineers. Lead the design, development, and maintenance of data pipelines, data warehouses, and data lakes, ensuring adherence to best practices. Collaborate closely with data analysts, data scientists, and stakeholders to understand their unique data requirements and translate them into robust technical solutions. Champion the implementation of data quality, data security, and privacy practices to ensure compliance with industry standards. Monitor and troubleshoot data pipelines, data warehouses, and data lakes to ensure optimal performance and availability. Provide technical guidance and mentorship to the data engineering team, fostering their growth and enhancing their technical capabilities. Stay updated on emerging technologies and tools, continuously evaluating and incorporating them to improve our data infrastructure. Requirements: An exceptional academic background in a relevant field, demonstrating a strong foundation in technical knowledge. Minimum of 4 years of hands-on experience in data engineering or a related field. Expertise in designing and developing data pipelines, data warehouses, and data lakes. Proficiency in cloud infrastructure, such as AWS or Azure, enabling effective utilisation of cloud-based solutions. Strong understanding of data modelling and schema design, ensuring efficient and scalable data structures. Analytical and problem-solving skills to tackle complex data challenges and derive actionable insights. Experience in leading and mentoring a team towards successful project outcomes. Excellent communication and collaboration skills to effectively work with cross-functional stakeholders. Job Owner: p.horlock-brown"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=a9ae0f17cb6fbe0d", "page": 2, "job_title": "Data Engineer", "company_name": "Proactive IT", "job_location": "Redhill", "job_type": "Permanent", "jobkey": "a9ae0f17cb6fbe0d", "date_posted": "5 days ago", "jobDescription": "9532BRM9 £40k – 45k per year Data Engineer – Crawley – Perm £40,000 -£45,000 p/a 3 Days a week on site (Flexible) Our client is urgently looking for a Data Engineer to join their team based in Redhill on a permanent basis. The Data Engineer designs and implements data flows/data sets to connect operational systems data for business intelligence and analytics that are easy to use. They will be key in the delivery of solutions for predictive analytics, using innovative ways to connect multiple data sources to draw insights from data. You will be rewarded with an excellent salary and a brilliant benefit package including, annual leave, pension scheme, healthcare, flexible/hybrid working, and many more perks! Data Engineer – Redhill – Perm Key Skills: At least 1 year in Azure experience Good understanding of Dimensional Modelling Azure Data tech stack database design, relational and dimensional modelling Delivery of ETL and Data solutions in cloud-based infrastructure. Knowledge of Data and Visualisation tools, primarily Power BI Must have a valid Visa and cannot provide Sponsorship. Data Engineer – Redhill – Perm Due to the volume of applications received for positions, it will not be possible to respond to all applications and only applicants who are considered suitable for interview will be contacted. Proactive Appointments Limited operates as an employment agency and employment business and is an equal opportunities organisation We take our obligations to protect your personal data very seriously. Any information provided to us will be processed as detailed in our Privacy Notice, a copy of which can be found on our website http://proactive.it/privacy-notice/"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=0431a378727200af", "page": 2, "job_title": "Data Engineer", "company_name": "Yolk Recruitment Ltd", "job_location": "London", "job_type": "Permanent", "jobkey": "0431a378727200af", "date_posted": "5 days ago", "jobDescription": " Location: London Sector: Technology &amp; Digital Job type: Permanent Salary: £60000.00 - £72000.00 per annum Contact: Ryan Harris Email: Ryan.Harris@yolkrecruitment.com Job ref: BBBH31543_1686923684 Published: 6 days ago Expiry date: 16 July 2023 Senior Data Engineer (AWS / GCP) | London | Hybrid (2 days per week onsite) | Up to £88,000 | 2 stage interview process Are you a highly skilled Data Engineer looking for a new challenge? Yolk Recruitment is excited to support a leading UK publisher in their search for a talented individual to join their team as a Senior Data Engineer. If you're ready to take your career to the next level, read on! In this role, you will be responsible for managing the performance, integrity, and security of the company's data. This includes supporting the development of a new multi-cloud Data Lake, designing and delivering a new B2B Data Warehouse, and integrating various data sources such as Google Analytics and eCommerce data. You will also be responsible for providing data sets for reporting applications, analyzing S3 data sources, and aligning existing and new processes to defined design patterns and coding standards. The role is based in their recently refurbished offices just off Trafalgar Square. They operate a hybrid working model with 2 days per week in the office. Key Responsibilities: Managing the performance, integrity, and security of the company's data Supporting the development of a new multi-cloud Data Lake Designing and delivering a new B2B Data Warehouse, integrating various data sources Migration of SSAS Cube into new B2B AWS Data Warehouse Align existing and new processes to defined design patterns and coding standards Maintain data standards, including adherence to the Data Protection Act Essential Criteria: Strong experience in a similar role Excellent problem-solving skills and attention to detail Strong SQL, Python, Airflow, and experience with Cloud environments (AWS, GCP) AWS data storage solutions (AWS Data Lake, Data Warehouse etc). Ideally you will also have exposure to Google Cloud. Main Benefits: Salary up to £72,000 25 days holiday (bank holidays on top) Flexible &amp; remote working options Got your attention? If you believe that you have the skills and experience for the role - then please get in touch. We also offer a referral scheme for any candidates whose details are passed to us that we successfully place. If you have any further questions then please contact Ryan Harris at Yolk Recruitment. *Please note, whilst we do our best to contact all candidates, due to the high number of applications we receive we cannot guarantee this for every role. If you have not heard anything from us within 7 days of applying - then unfortunately you have been unsuccessful. Please keep an eye on our website for more opportunities.* 'Yolk Recruitment Ltd acts as an employment business for temporary positions and an employment agency for permanent positions. Yolk Recruitment Limited is committed to equal opportunity and diversity. Suitable candidates with equivalent qualifications and more or less experience can apply. By applying for this job you accept the T&amp;C's, Privacy Policy and Disclaimers which can be found at http://www.yolkrecruitment.com/' "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=d283383c44f2aa16", "page": 2, "job_title": "Azure Data Engineer", "company_name": "Next Ventures Limited", "job_location": "London", "job_type": null, "jobkey": "d283383c44f2aa16", "date_posted": "2 days ago", "jobDescription": " Practice Data Technologies Business Intelligence Jobs and Data Recruitment Location London, United Kingdom Type Contract Key responsibilities Support the day-to-day orchestration and running of ETL processes and monitor and investigate data issues as they might arise Build and adapt analytical data models in Power BI and Power Query to meet functional business requirements and performance needs Analyse the analytical solutions landscape and act as a technical leader on the tools and approaches to adopt to increase automation, performance, and fault-tolerance in financial planning and analysis Support business users and analysts on ad-hoc reporting and visualisation projects Proactively take initiatives to increase the value that our reporting and insights solutions bring to users, by evolving and optimizing the solutions strategically Develop a deep understanding of the data sets and sources available across the data platform, and match use cases with the most appropriate data source Support on ad-hoc projects with your problem-solving skills and technical expertise Requirements Extensive experience creating and working with tabular and multidimensional models (proficient in DAX, MDX, and SSAS or Power BI data modelling) Strong SQL skills Deep understanding of database fundamentals, including relational database design In-depth understanding of database management systems, online analytical processing (OLAP) and ETL framework Fluency in Python Experience with GCP and Azure, or similar Experience building machine learning pipelines (preferred) Nice to have A degree in IT, business management, or equivalent qualifications Experience working with a finance/controlling function An affinity with data visualisation Advanced expertise in Excel visualisations (Cube functions, Power Pivot, etc), and creating Paginated Reports Experience in data/project governance and management Experience working with SAP "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=99c1e9710e013acc", "page": 2, "job_title": "Principal Data Engineer", "company_name": "Just Retirement", "job_location": "London", "job_type": null, "jobkey": "99c1e9710e013acc", "date_posted": "1 day ago", "jobDescription": " 20.6.23 IT The Principal Data Engineer is responsible for own the design and aspects of the implementation of Big Data and BI solutions using the Microsoft Azure platform. The Principal Data Engineer is expected to evangelise and educate others on engineering design and development standards. The Principal Data Engineer leads the data engineering function."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=edc89b35f57b7253", "page": 2, "job_title": "Senior Data Engineer/Architect – Financial Mainly Remote London", "company_name": "Noir Consulting", "job_location": "London", "job_type": null, "jobkey": "edc89b35f57b7253", "date_posted": "3 days ago", "jobDescription": "Senior Data Engineer/Architect - Financial Mainly Remote London (Tech stack: Azure, Azure SQL as a service, Cosmos DB, Azure event triggering hub, any experience Azure SSIS for Data Transport a bonus. For the future we would be interested in Azure Synpase, Databricks) We have several fantastic new roles including this Senior Data Engineer to join am exponentially growing global financial. This is your chance to work for one of the most ambitious companies in this sector who has made somewhere in the order of 15-20 acquisitions over the last year! They are growing at a phenomenal pace and need several new people to join their new and growing IT team! These are great opportunities for those of you who have experience of Azure, SQL as a Service, Cosmos DB, Azure even triggering hub, thrive on the autonomy and feel ready to be part of something fresh and new in a team and help lead the way forward. Our client specialise in delivering risk management solutions to individuals and businesses for almost 100 years. With more than 10, 000 teammates in almost 350 locations across the globe our client are committed to providing innovative strategies to help customers protect what they value most. Any background in the Insurance/Risk markets would be advantageous. We are looking for a proven Senior Data Engineer with experience of technologies such as Azure, SQL as a Service, Cosmos DB, Azure even triggering hub as well as strong Architecture. The current system is a monolithic system utilizing the older SQL Server technologies so this is a great opportunity to effectively break that old system up and redesign a new one using the latest tech. a 2nd version of the old system. A complete revamp! Successful candidates are likely to have 5-10 experience in data engineering with some strong experience of Architecture. This person needs to be someone with the experience with new technologies like Azure, Azure SQL as a service, Cosmos DB, Azure event triggering hub but the background and experience to understand what's already in place. They will be a technology leader and will work with the other programmers on this. To apply, candidates will have strong architecture experience, experience with Azure SQL as a service, Cosmos DB, Azure event triggering hub, any experience in areas like Azure SSIS for Data Transport would be a bonus. For the future we would be interested in Azure Synpase, Databricks. Mainly remote role with 1/month in London City office."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=d515514bd171b87c", "page": 2, "job_title": "Data Engineer", "company_name": "Red Commerce", "job_location": "London", "job_type": "", "jobkey": "d515514bd171b87c", "date_posted": "5 days ago", "jobDescription": " Data Engineer /Based in London Remote with 1 day per week or 1 week per month in Stockholm / 6 months / Start ASAP This role will be embedded in the Controlling Centre of Excellence function for COS Key responsibilities: Support the day-to-day orchestration and running of ETL processes and monitor and investigate data issues as they might arise Build and adapt analytical data models in Power BI and Power Query to meet functional business requirements and performance needs Analyze the analytical solutions landscape and act as a technical leader on the tools and approaches to adopt to increase automation, performance, and fault-tolerance in financial planning and analysis Support business users and analysts on ad-hoc reporting and visualisation projects Proactively take initiatives to increase the value that our reporting and insights solutions bring to users, by evolving and optimising the solutions strategically Develop a deep understanding of the data sets and sources available across the data platform, and match use cases with the most appropriate data source Support on ad-hoc projects with your problem-solving skills and technical expertise Requirements: Extensive experience creating and working with tabular and multidimensional models (proficient in DAX, MDX, and SSAS or Power BI data modelling) Strong SQL skills Deep understanding of database fundamentals, including relational database design In-depth understanding of database management systems, online analytical processing (OLAP) and ETL framework Fluency in Python Experience with GCP and Azure, or similar Experience building machine learning pipelines (preferred) Nice to have: A degree in IT, business management, or equivalent qualifications Experience working with a finance/controlling function An affinity with data visualisation Advanced expertise in Excel visualisations (Cube functions, Power Pivot, etc), and creating Paginated Reports Experience in data/project governance and management Experience working with SAP Required cloud certification: DP-500 (Consultant is expected to have certificate at latest 1 month after start, if not already certified.) Reference CR/107530_1686909011"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=949041b8ba86560d", "page": 2, "job_title": "Lead Data Engineer", "company_name": "Datasource", "job_location": "London", "job_type": "Permanent", "jobkey": "949041b8ba86560d", "date_posted": "5 days ago", "jobDescription": " Introduction We are looking for a Data Manager to work with external clients to take data products and data platforms and support the implementation of this into the client environment. My client is a global leading defence consultancy who support their clients with the build, implementation, and enhancements of Smart Buildings across the world. As my client are a consultancy, you will be expected on-site 2 days per week, as well as travel to client sites when required. You will also need to hold or undergo an SC Security Clearance to be considered for this role. You will need to be a sole British National due to this requirement. Key responsibilities Work with developers and managers to understand and define the data landscape and how it relates to Data strategy Translate user requirements into designs to provide effective data solutions Support work streams and the delivery team Create documentation and presentations of solutions for the team Identify improvements Mentor and support the data team Contribute to the ongoing development of documentation and processes Skills &amp; experience Experience and knowledge of Azure Cloud is required Experience designing and delivering data solutions with Azure Experience with leading architectural engagements Solid understanding of engineering delivery cycle including Agile and DevOps Experience with Governance, Architecture, Data Modelling, ETL / ELT, Data Lakes, Data Warehousing, Master Data, and Power BI. Experience working with Azure First Party Services including Azure SQL, Data Factory, Data Lake, Synapse, Purview and Power BI. Additional benefits Private Medical Insurance. Permanent Health Insurance. Life Assurance Personal Accident Cover. 25 days holiday (+ x8 public holidays). Our client is committed to providing a diverse and inclusive workplace and welcomes applications from all backgrounds. RECOMMEND A FRIEND: If you have professional friends/colleagues who would be interested in one of our roles and our excellent levels of service too, we'd like to recognise your recommendations with a 'thank you' of our own. For every colleague you refer who then starts a role through Datasource either Contract or Permanent, we will send you £250 of Love to Shop Gift Vouchers. You will be required to hold a minimum of SC Clearance. If you do not hold an active SC clearance, please familiarise yourself with the vetting process before applying. (c) Copyright Datasource Computer Employment Limited 2023. "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=0513c5b903e03b99", "page": 2, "job_title": "Senior Data Engineer", "company_name": "Harnham", "job_location": "London", "job_type": "Permanent", "jobkey": "0513c5b903e03b99", "date_posted": "2 days ago", "jobDescription": " INFO SALARY: £65000 - £75000 LOCATION City of London JOB TYPE Permanent Role: Senior Data Engineer Location: London 2 days a week in the office Salary Up to £75,000 Are you a highly skilled Senior Data Engineer seeking a unique work arrangement in London? We are collaborating with our esteemed client, a leading organisation, to find a talented Senior Data Engineer to join their team. In this role, you will have the opportunity to work full-time while enjoying the flexibility of spending two days per week working from the office. Responsibilities: Design and maintain robust data architecture, including data modeling, data warehousing, and database management systems. Collaborate with business analysts, software developers, and stakeholders to identify data needs and develop effective solutions. Support the development and maintenance of the data warehouse, enabling advanced analytics and reporting. Ensure data quality, accuracy, and completeness through proactive monitoring and corrective actions. Stay updated with emerging trends and recommend data management solutions to enhance the data architecture. Assist in implementing data security and privacy policies to protect sensitive information. Requirements: Bachelor's degree in Computer Science, Information Technology, or related field. Strong experience in data architecture, data modeling, and database design. Proficiency in SQL Server and familiarity with Azure SQL and other cloud technologies. Knowledge of data warehousing, ETL processes, and data governance principles. Proven experience in programming for automated data processing and analysis. Excellent communication and collaboration skills. If you are interested please email me at or apply directly to this advert. CONTACT Cameron Mason Recruitment Consultant "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=4714aaa89a50c5cc", "page": 2, "job_title": "Lead Data Engineer", "company_name": "Cabinet Office", "job_location": "London", "job_type": "Full-time, Permanent", "jobkey": "4714aaa89a50c5cc", "date_posted": "7 days ago", "jobDescription": " Details Reference number 295639 Salary £55,794 - £61,848 A Civil Service Pension with an average employer contribution of 27% Job grade Grade 7 Contract type Permanent Business area CO - Situation Centre - The SitCen brings together a unique set of skilled people, capabilities and experience, operating 24/7 and extended hours to support horizon scanning and crisis-response across the full range of national risks, from civil emergencies to national security Type of role Analytical Architecture and Data Digital Working pattern Full-time Number of jobs available 2 Contents Location About the job Benefits Things you need to know Apply and further information Location London About the job Job summary The SitCen brings together a unique set of skilled people, capabilities and experience, operating 24/7 and extended hours to support horizon scanning and crisis-response across the full range of national risks, from civil emergencies to national security issues. We work at the sharpest end of the Government’s crisis response, supporting our leaders’ in decision-making. New technology and analytical techniques are vital to our work. We have joined forces with partners across and beyond Government to innovate and experiment. Bringing together the best minds, the latest technology and a spirit of collaboration, the SitCen helps to bring the absolute best of Government to the toughest challenges that our nation faces. Within the SitCen, we pride ourselves on our team culture, which is operationally and customer focussed, innovative, compassionate, and inclusive, and continuously learning. Job description You will lead the Data Engineering team and drive best practice. You will be acquiring data sets from multiple sources at varying levels of maturity. You will curate and catalogue this data in partnership with the Data Scientists and analysts. Solutions will be developed using the Gov PaaS environment as well as AWS. You will be using and developing Data Engineering capability provided within the AWS environment. There is extensive use of infrastructure as code within a structured development. There is extensive use of infrastructure as code within a structured development environment. You will deliver capability using an appropriate structured process. Agile and DevOps experience would be an advantage. You can produce data models and understand where to use different types of data models. You have experience of a wide range of data engineering tools. You understand industry-recognised data-modelling patterns and standards. Person specification We are seeking skilled individuals with relevant technical skills, and welcome applicants from data engineering, devops, analytical, or data science backgrounds. You will be keen to learn cutting-edge skills at the intersection of data engineering, software development, analysis and data science. You will be part of the SitCen Technology team with a key focus on building Data pipelines for the ingestion and transformation of data from across government. Communication skills (data): You know how to communicate to and between technical and non-technical stakeholders as well as facilitate discussions within a multidisciplinary team, with potentially difficult dynamics. You know how to manage different perspectives. Data development process: You can design, build and test data products that are complex or large-scale. You know how to build teams to provide data integration services. You have experience of working with AWS Cloud Data Engineering technologies. You understand how to manage data sharing in a secure and compliant manner, balancing the right levels of access against any sensitivities. Problem resolution (data): You know how to respond to problems in databases, data processes, data products and services as they occur. You can initiate actions, monitor services and identify trends to resolve problems. You can determine the appropriate remedy and assist with implementation of it as well as preventative measures. Programming and build (data engineering): You have experience of working with modern software development techniques such as: DevOps; Git-ops; continuous testing, development and integration; configuration as code; and infrastructure as code. You will be using and developing Data Engineering capability provided within the AWS environment. You will deliver capability using an appropriate structured process. Agile and DevOps experience would be an advantage. You will be an experienced Data Engineer with the following technical skills: Strong AWS experience (ideally including Lambda, Glue, Redshift, Sagemaker, IAM, Athena, EC2, Kinesis, Cloudwatch, Cloudtrail) Python SQL DevOps background with good knowledge of cloud-based IAC technologies. Terraform or serverless Git as version control Familiar with CI/CD Any exposure to Machine Learning is a bonus Behaviours We'll assess you against these behaviours during the selection process: Seeing the Big Picture Managing a Quality Service Communicating and Influencing Delivering at Pace Leadership Technical skills We'll assess you against these technical skills during the selection process: Data Engineering Design Coding Skills Benefits Alongside your salary of £55,794, Cabinet Office contributes £15,064 towards you being a member of the Civil Service Defined Benefit Pension scheme. Find out what benefits a Civil Service Pension provides. Learning and development tailored to your role An environment with flexible working options A culture encouraging inclusion and diversity A Civil Service Pension which provides an attractive pension, benefits for dependants and average employer contributions of 27% A minimum of 25 days of paid annual leave, increasing by one day per year up to a maximum of 30 Things you need to know Selection process details This vacancy is using Success Profiles (opens in a new window), and will assess your Behaviours, Experience and Technical skills. As part of the application process you will be asked to complete a CV and Technical skills statement. Behaviours and technical skills will be assessed on both application and in interview. Should a large number of applications be received, an initial sift may be conducted using the lead behaviour, Seeing the Big Picture. Candidates who pass the initial sift may be progressed to a full sift, or progressed straight to assessment/interview. Expected Timeline (subject to change) Expected sift date – w/c 17th July Expected interview date/s – w/c 31st July Interview location - remote via google meet. All applicants will need to undergo SC clearance and be willing to undergo DV in the future. The nature of this post may occasionally require you to respond to unexpected events/crisis. At such times you will be required to work outside of your conditioned hours at short notice. This could be on any day including weekends. During a national crisis that requires COBR level meetings, it may be necessary for the successful candidate to move to working a shift pattern in partnership with colleagues. This would be covered by Cabinet Office shift allowances. Whilst the SitCen will be required to operate 24/7, we aspire to find ways of operating that will enable recruitment from a diverse talent pool. It is our intent to develop a network of surge pools from across government that will enable round the clock working where necessary, whilst placing a premium on staff wellbeing. There are a range of ways in which this job could be done depending on the quantity of hours worked. The responsibilities could be split (or reduced) as part of a job share or part time working pattern, and there are some elements of the job that may be suitable for home working on an occasional basis. If you are a person with disabilities, and something in this job advert worries you, come and talk to us about your strengths and how we might tailor the job to be flexible and inclusive of your needs. Further Information A reserve list may be held for a period of 12 months from which further appointments can be made. Any move to Cabinet Office from another employer will mean you can no longer access childcare vouchers. This includes moves between government departments. You may however be eligible for other government schemes, including Tax Free Childcare. Determine your eligibility at https://www.childcarechoices.gov.uk If successful and transferring from another Government Department a criminal record check may be carried out. In order to process applications without delay, we will be sending a Criminal Record Check to Disclosure and Barring Service on your behalf. However, we recognise in exceptional circumstances some candidates will want to send their completed forms direct. If you will be doing this, please advise Government Recruitment Service of your intention by emailing Pre-EmploymentChecks.grs@cabinetoffice.gov.uk stating the job reference number in the subject heading. The successful candidate will need to initially undergo SC clearance once successful in the role, however once settled in to the role will need to be willing to undergo Developed Vetting (DV) in order to be successful in their application. SC clearance, which would normally need 5 years UK residency in the past 5 years. This is not an absolute requirement, but supplementary checks may be needed where individuals have not lived in the UK for that period. This may mean your security clearance (and therefore your appointment) will take longer or, in some cases, not be possible. New entrants are expected to join on the minimum of the pay band. Applicants who are successful at interview will be, as part of pre-employment screening, subject to a check on the Internal Fraud Database (IFD). This check will provide information about employees who have been dismissed for fraud or dishonesty offences. This check also applies to employees who resign or otherwise leave before being dismissed for fraud or dishonesty had their employment continued. Any applicant’s details held on the IFD will be refused employment. A candidate is not eligible to apply for a role within the Civil Service if the application is made within a 5-year period following a dismissal for carrying out internal fraud against government. This role is full time only. Applicants who wish to work an alternative pattern are welcome to apply however your preferred working pattern may not be available and you should discuss this with the vacancy holder before applying. Please note terms and conditions are attached. Please take time to read the document to determine how these may affect you. If you are experiencing accessibility problems with any attachments on this advert, please contact the email address in the 'Contact point for applicants' section. Reasonable Adjustment If a person with disabilities is put at a substantial disadvantage compared to a non-disabled person, we have a duty to make reasonable changes to our processes. If you need a change to be made so that you can make your application, you should: Contact Government Recruitment Service via cabinetofficerecruitment.grs@cabinetoffice.gov.uk as soon as possible before the closing date to discuss your needs. Complete the ‘Assistance required’ section in the ‘Additional requirements’ page of your application form to tell us what changes or help you might need further on in the recruitment process. For instance, you may need wheelchair access at interview, or if you’re deaf, a Language Service Professional. Feedback will only be provided if you attend an interview or assessment. Security Successful candidates must undergo a criminal record check. Successful candidates must meet the security requirements before they can be appointed. The level of security needed is security check (opens in a new window). See our vetting charter (opens in a new window). People working with government assets must complete baseline personnel security standard (opens in new window) checks. Nationality requirements This job is broadly open to the following groups: UK nationals nationals of Commonwealth countries who have the right to work in the UK nationals of the Republic of Ireland nationals from the EU, EEA or Switzerland with settled or pre-settled status or who apply for either status by the deadline of the European Union Settlement Scheme (EUSS) (opens in a new window) relevant EU, EEA, Swiss or Turkish nationals working in the Civil Service relevant EU, EEA, Swiss or Turkish nationals who have built up the right to work in the Civil Service certain family members of the relevant EU, EEA, Swiss or Turkish nationals Further information on nationality requirements (opens in a new window) Working for the Civil Service The Civil Service Code (opens in a new window) sets out the standards of behaviour expected of civil servants. We recruit by merit on the basis of fair and open competition, as outlined in the Civil Service Commission's recruitment principles (opens in a new window). The Civil Service embraces diversity and promotes equal opportunities. As such, we run a Disability Confident Scheme (DCS) for candidates with disabilities who meet the minimum selection criteria. Apply and further information This vacancy is part of the Great Place to Work for Veterans (opens in a new window) initiative. Once this job has closed, the job advert will no longer be available. You may want to save a copy for your records. Contact point for applicants Job contact : Name : Richard Newell Email : richard.newell@cabinetoffice.gov.uk Recruitment team Email : cabinetofficerecruitment.grs@cabinetoffice.gov.uk Further information Appointment to the Civil Service is governed by the Civil Service Commission’s Recruitment Principles. If you feel that your application has not been treated in accordance with the Recruitment Principles, and wish to make a complaint, then in the first instance you should contact Government Recruitment Service at: cabinetofficerecruitment.grs@cabinetoffice.gov.uk. If you are not satisfied with the response that you receive, then you can contact the Civil Service Commission at: info@csc.gov.uk. For further information on the Recruitment Principles, and bringing a complaint to the Civil Service Commission, please visit their website at: https://civilservicecommission.independent.gov.uk. "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=4e4623af04ac0038", "page": 2, "job_title": "Data Engineer", "company_name": "Eames Consulting", "job_location": "London", "job_type": "Fixed term contract", "jobkey": "4e4623af04ac0038", "date_posted": "5 days ago", "jobDescription": " Job Details Sector: DevOps, Infrastructure &amp; Cloud Location: City of London Job Ref: DCO_1686824441 Job Type: Contract Salary: £500 - £550 per day (Outside IR35) Contact: Zakir Alam Job Description Data Engineer - Insurance client Initial 6 Month Contract £500/day (Outside IR35) Hybrid I am currently recruiting for a Data Engineer for a London Market Insurance client of mine. The client is building a new team and are looking for candidates who are experienced with DynamoDB, Snowflake, DBT and Rockset. The role is hybrid and Outside IR35 Insurance or Financial Service is essential! Eames Consulting is acting as an Employment Business in relation to this vacancy. "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=0ac4771612db26f0", "page": 2, "job_title": "Data Engineer", "company_name": "Oliver James Associates", "job_location": "London", "job_type": "Permanent", "jobkey": "0ac4771612db26f0", "date_posted": "3 days ago", "jobDescription": " An Insurance broker are looking for a Junior Data engineer to join their team. This is an exciting opportunity for a hands-on Data Engineer to be responsible for developing and maintaining scalable data products and systems that support data processing, transformation, and storage. Responsibilities: Development, testing and maintenance of company data solutions and associated ETL / ELT pipelines, ensuring all source control and continuous integration practices Collaborate with cross-functional teams to understand and estimate data requirements, implement new data-driven solutions and design data models that support data-driven decision-making Develop and maintain documentation on data pipelines, data models, and data dictionaries Implement data quality checks, data validation, and data cleansing procedures Skills required: Strong experience of the Azure data services (Azure Synapse, Azure Data Factory, Azure Databricks, Azure SQL) Experience with database technologies such as SQL and NoSQL databases Proficiency in at least one programming language such as Python or Scala CI/CD, Azure DevOps Pipelines and Releases Experience with big data technologies such as Apache Spark Experience with cloud platforms, preferably Azure Expertise in data modelling, data warehousing and ELT/ETL processes "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=a9ca2ab4f97eef2f", "page": 3, "job_title": "Senior Data Engineer - Advanced Technology", "company_name": "Ocado Group", "job_location": "Welwyn Garden City", "job_type": null, "jobkey": "a9ca2ab4f97eef2f", "date_posted": "5 days ago", "jobDescription": " Senior Data Engineer - Advanced Technology | Welwyn Garden City | Hybrid (2 days office) About us: Ocado Technology is putting the world’s retailers online using the cloud, robotics, AI, and IoT. We develop the innovative software and systems that power Ocado.com, the world’s largest online-only grocery retailer as well as the global ‘Ocado Smart Platform’. With everything from websites to fully autonomous warehouse that we design in-house, our employees need to be specialists in a wide range of technologies to help drive our business. We champion a value-led culture to get our teams working at their very best and to help create a collaborative working environment that our people love. Core values of Trust, Autonomy, Craftsmanship, Collaboration and Learn Fast help drive our innovative culture. About the role: Data already powers insights, products and capabilities in every part of Ocado Technology but we’re really just getting started. We are growing our global Data Engineering team focussing on the Advanced Technology stream with the mission to serve reliable and relevant product data to internal and external customers. This is important to help product managers make better decisions on how to take Dexterous Manipulation Robotics and Autonomous Mobility capabilities to the next level. The Senior Data Engineer’s role is to design, build and maintain scalable, robust and performant data pipelines and related systems that meet technical and functional requirements. Data engineering work takes place fully in GCP with pre-ingested data coming from our applications. You will: Design, implement and optimise Advanced Technology’s data schemas, robotics data models and reporting tables Collaborate with platform teams to select data storage, ingestion, and digestion technologies to meet consumption and ingestion patterns Proactively design data unit tests to ensure quality and gain visibility into potential anomalies Monitor data objects and provide operational support Promoting best practices in data engineering (i.e naming conventions, pipeline design standards, DBT model best practices) Stay up-to-date with industry developments including conferences, launch of new technologies and new patterns in data engineering We would also expect you to: Embrace change and solve problems that could prevent us from reaching our goals Collaborate with any colleagues / stakeholders as needed What we’re looking for: You have a strong grounding in SQL, BigQuery and Excel Experience working with data using a language such as Python Strong experience in analytics, particularly in a senior/lead role Experience with the modern data stack, including tools such as dbt, Looker, Data Studio You are proactive, identifying issues and opportunities before having to be told to do so. What do I get in return: Hybrid working model (2 days in the office) 30 days ‘work from anywhere’ policy + Remote working for the month of August Wellbeing support through Apps such as Unmind and an Employee Assistance Programme 25 days annual leave, rising to 27 days after 5 years service (plus optional holiday purchase) Pension scheme (various options available including employer contribution matching up to 7%) Private Medical Insurance 22 weeks paid maternity leave and 6 weeks paid paternity leave (once relevant service requirements complete) Train Ticket loan (interest-free) Cycle to Work Scheme Opportunity to participate in Share save and Buy as You Earn share schemes 15% discount on Ocado.com and free delivery for all employees Income Protection(can be up to 50% of salary for 3 years) and Life Assurance(3 x annual salary) Free shuttle bus to and from Welwyn Train Station to the Welwyn offices Share options + increased free shares annually "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=f19a49f7c7ff0e48", "page": 3, "job_title": "Data Engineer (Blockchain)", "company_name": "Understanding Recruitment", "job_location": "London", "job_type": "Permanent", "jobkey": "f19a49f7c7ff0e48", "date_posted": "3 days ago", "jobDescription": " BBBH11776_1687089830 Posted: 18/06/2023 £70000 - £90000 per annum + Company Benefits London Permanent Join the Future of Blockchain and Crypto as a Data Engineer! I am searching for a Data Engineer to join a cutting-edge Web3 &amp; Crypto house and be a key player in designing and developing ground-breaking products with a focus on MEV (Miner Extractable Value). Unleash your technical prowess as you work hands-on to transform ambitious concepts into practical, high-impact solutions! Location: London (Hybrid Week) You will be joining a collaborative team innovating greenfield projects and building from the ground up. Leveraging your background in Python and cloud tech, you will gain exposure across Web3, amongst a global team made up of the brightest minds in tech. Ready to shape the future? Join the team and make your mark in the world of MEV and beyond. ! "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=84fd43ed5e818958", "page": 3, "job_title": "AWS Data Engineer - 6 Months - Inside IR35 - Databricks Required", "company_name": "Opus Recruitment Solutions", "job_location": "London", "job_type": null, "jobkey": "84fd43ed5e818958", "date_posted": "5 days ago", "jobDescription": " I am currently on the lookout out for multiple AWS data engineers to join one of my consultancy clients on a 6 months basis. The end client who work in financial service industry are looking to migrate their data function into the AWS tech stack and as such need multiple pair of hands to help them out. The contract: 6 months Remote working (ideally you are still able to attend important meetings in London) Requirements Extensive experience working as a Data Engineer Databricks Reuirement Extensive experience working in the AWS tech stack (AWS Glue, Redshift etc.) Extensive Python experience Extensive SQL experience Previous experience migrating into AWS The role is urgent as they are looking to build out the whole team in the next couple of weeks. If you are on the market please send me over your up to date CV as soon as you can!"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=243fab94b46f208f", "page": 3, "job_title": "Lead Data Engineer - Oracle/SQL - Hybrid", "company_name": "Nigel Frank International Limited", "job_location": "London", "job_type": null, "jobkey": "243fab94b46f208f", "date_posted": "2 days ago", "jobDescription": " newRef: NFIBI150623DM_1686820597 Lead Data Engineer - Oracle/SQL - Hybrid England £40,000 to £60,000 GBP Developer/Programmer Role Skills: Oracle, SQL, AWS, Snowflake, ETL, Pipelines, Engineer, Engineering, Lead, Mentor Level: Senior Job description Lead Data Engineer - Oracle/SQL - Hybrid NFIBI150623DM_1686820597 Lead Data Engineer - Oracle/SQL - Hybrid I am working with a leading insurance organisation, and they are currently looking for a Lead Data Engineer to join their fast growing team. Within this role you will be working mainly on end-to-end solutions and development. You are going to be designing and implementing ETL pipelines on various technologies, data quality monitoring, migrating from Oracle to AWS within the next few years. Also, you will be managing the agile delivery process and you will be a leading and managing a team of engineers too. This is a permanent salaried position paying between £45,000 - £58,000 depending on the strength of your skill-set, working 2x/week in the office in London or Norwich (whichever is closer to you) and offers great benefits such as the opportunity to work for a fast growing company, with fun working environment and the opportunity to progress and get training. Minimum qualifications required: Strong experience developing ETL pipelines Strong experience with SQL and Oracle Experience with cloud migration projects Excellent communication skills This is a fantastic opportunity to work with an established team and up-skill with exciting technologies. Do not miss this exciting and unique opportunity and reach out to have a chat. To discuss in more detail, please send your CV d.moore1@nigelfrank.com or alternatively, call Danielle Moore on 0191 338 7577 "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=4a54fda4bf015df4", "page": 3, "job_title": "Lead Data Engineer - Analytics & Data Platform (Fixed term 12 months)", "company_name": "T. Rowe Price", "job_location": "London", "job_type": "Full-time", "jobkey": "4a54fda4bf015df4", "date_posted": "1 day ago", "jobDescription": " There is a place for you at T. Rowe Price to grow, contribute, learn, and make a difference. We are a premier asset manager focused on delivering global investment management excellence and retirement services that investors can rely on today and in the future. The work we do matters. We invite you to explore the opportunity to join us and grow your career with us. Lead Data Engineer Overview The Data Office team at T. Rowe Price is playing a key role in helping build the future of financial services, working together with business partners to create client experiences that are changing the way people invest. You will work with smart, talented people across our business. We will expect you to be agile and to think outside the box. In return, we will give you challenging work that makes an impact and brings opportunities to learn and grow, and a collaborative culture that encourages every member of our team to bring their point of view to the table—because that is how we help our clients succeed. You will be an individual contributor on the Analytics and Data Platform engineering team responsible for architecting, building, testing, and maintaining the data platform. You will be responsible for: Contributing to the platform’s architectural design Development and testing of the integration, modelling, data persistence and querying tools and analytical systems Data pipeline implementation, maintenance and testing Metadata management processes and tools Monitoring the overall performance and stability of the pipelines Implementing data curation, metadata management and data quality tooling Engaging with our business and technology partners to ensure that the platform fully meets the firm’s needs Preferred Technical experience/skills 12+ years of experience working as a Java developer. Strong understanding of AWS ecosystems like Lambdas, step functions and ECS services. Experience in architecting cloud components, integration layer and data storage. Python engineering skills with exposure to pandas, Numpy. R could be a plus. Experience with data stack technologies, such as Apache Iceberg &amp; Spark. Exposure to Apache Airflow, Prefect, Dagster, DBT would be a plus. Hands on experience on RDBMS like PostgreSQL would be a plus. Expertise in data analysis with exposure to data services (such as Glue, Lake Formation, EMR, EventBridge, Athena, etc.) &amp; metadata management tools (such as Amundsen, Atlas, DataHub, OpenDataDiscovery, Marquez, etc.), Experience building modern enterprise-wide data and analytics systems in a financial services organisation with an understanding of the asset management business and/or financial markets Lead Skills Proven experience of leading small to mid-size team of engineers. Responsible for growth, learning and mentorship of the team. Experience in managing short and long term product / requirement roadmaps. Experience with Agile Scrum model would be a plus. T. Rowe Price operates a hybrid working model. Commitment to Diversity, Equity, and Inclusion: We strive for equity, equality, and opportunity for all associates. When we embrace the power of diversity and create an environment where people can bring their authentic and best selves to work, our firm is stronger, and we create greater value for our clients. Our commitment and inclusive programming aim to lift the experience for each associate and builds allies for our global associate community. We know that a sense of belonging is key not only to your success at the firm, but also to your ability to bring your best each day. T. Rowe Price is an equal opportunity employer and values diversity of thought, gender, and race. We believe our continued success depends upon the equal treatment of all associates and applicants for employment without discrimination on the basis of race, religion, creed, colour, national origin, sex, gender, age, mental or physical disability, marital status, sexual orientation, gender identity or expression, citizenship status, military or veteran status, pregnancy, or any other classification protected by country, federal, state, or local law. "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=15932d8d8af73019", "page": 3, "job_title": "Senior Core Data Engineer", "company_name": "Sky", "job_location": "Osterley", "job_type": "Full-time", "jobkey": "15932d8d8af73019", "date_posted": "Today", "jobDescription": " Sky's Core Engineering team has an extraordinary new opportunity for a Senior Data Core Engineer to join our team to contribute and bring fresh ideas to the table. Broadcast Technologies is pivotal in technology innovation of these systems that support Content origination &amp; playout, Content contribution &amp; distribution areas and also developing their control and monitoring capabilities. As a valuable member of the team, you’ll help support, drive improvements and build new functionality on our platforms so that Sky can continue to provide the amazing content that our customers love! You will be working across pioneering projects as Broadcast teams at Sky look to Cloud solutions for scale and agile deployment. Collaborating with like-minded problem solvers across the company and driving the development of these platforms forward. What you'll do Encourage and coordinate a team of hardworking engineers by promoting the best technology and software development practices into the team with passion and enthusiasm! IP Networks + Data Pipelines: Develop and support the ingestion, processing, and analysis of data for modelling, reporting, visualisation and business analytics purposes! Design and development of operational solutions that use Machine Learning, Analysis and Data Engineering to utilise our rich data assets - including viewing behaviours and content engagement on multiple platforms (linear, on demand, streaming etc), online engagement with Sky digital (apps, website), customer service interactions, service quality and performance information and customer metrics. Working on the strategic large scale, multi-tenanted Kubernetes platform central to key propositions running on a global scale, including NOW, Peacock, and Sky. Delivery of well tested data pipelines to achieve automated CI/CD Diverse set of opportunities within internal teams, depending on personal interests across Software Engineering, SRE, Data, and Security Engineering teams What you’ll bring Experience performing analysis across data warehousing projects, applying principles in terms of dimensional modelling and ETL pipeline design Proven understanding in Linux and Automating tasks using tools such as Jenkins, GitLab CI/CD &amp; scripting languages like Python, Shell etc Strong Experience using SQL, and experience with cloud-based data warehouse/big data. A curios analytical mind and confidence in synthesising and evaluating either quant or qual data and turning them into meaningful insights. Basic programming experience, Python preferred. Familiar with software Engineering and SRE standard processes, Testing strategies, and CI/CD The rewards There's one thing people can't stop talking about when it comes to #LifeAtSky: the perks. Here’s a taster: Sky Q, for the TV you love all in one place The magic of Sky Glass at an outstanding rate A generous pension package Private healthcare Discounted mobile and broadband A wide range of Sky VIP rewards and experiences How you’ll work – hybrid working The world has changed. And so, have we. We’ve embraced hybrid working and split our time between outstanding office spaces and the convenience of working from home. You’ll find out more about what hybrid working looks like for your role later on in the recruitment process. Your office space Osterley Our Osterley Campus is a 10-minute walk from Syon Lane train station. Or you can hop on one of our free shuttle buses that run to and from Osterley, Gunnersbury, Ealing Broadway and South Ealing tube stations. There are also plenty of bike shelters and showers. On campus, there are 13 subsidised restaurants, cafes, and a Waitrose. You can keep in shape at our subsidised gym, catch the latest shows and movies at our cinema, get your car washed, and even get pampered at our beauty salon. We'd love to hear from you Inventive, forward-thinking minds come together to work in Tech, Product and Data at Sky. It’s a place where you can explore what if, how far, and what next. But better doesn’t stop at what we do, it’s how we do it, too. We embrace each other’s differences. We support our community and contribute to a sustainable future for our business and the planet. If you believe in better, we’ll back you all the way. Just so you know: if your application is successful, we’ll ask you to complete a criminal record check. And depending on the role you have applied for and the nature of any convictions you may have, we might have to withdraw the offer. "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=432fcfbdecd1acd2", "page": 1, "job_title": "Data Engineer", "company_name": "Understanding Recruitment", "job_location": "London", "job_type": "Permanent", "jobkey": "432fcfbdecd1acd2", "date_posted": "3 days ago", "jobDescription": " BBBH11725_1687089534 Posted: 18/06/2023 £55000 - £65000 per annum + Company Benefits London Permanent Do you want to innovate greenfield projects and revolutionise PropTech? I am searching for a Data Engineer to join a cutting edge PropTech team that are building a state-of-the-art data platform that is revolutionising Real Estate! You will work on blue sky projects, working alongside and agile and dynamic team in designing and implementing data pipelines, analytics, and reporting systems, empowering teams with cutting-edge insights. London based office (1x per fortnight in office). Collaborate closely with the team of data scientists and engineers, driving the technical stack and shaping the future of our platform. You will gain exposure in creating cutting-edge AI Solutions and play a hands-on role in delivering exceptional value to teams. You will have a background in Python and cloud experience (AWS, Azure or GCP). Could this be of interest? ! "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=ae11becfdc623bf7", "page": 1, "job_title": "Big Data Engineer", "company_name": "Morgan McKinley", "job_location": "London", "job_type": null, "jobkey": "ae11becfdc623bf7", "date_posted": "7 days ago", "jobDescription": " Senior Big Data Engineer London 2 days a week 6 months £710 PAYE inclusive of holiday Morgan McKinley is currently working with a leading bank, who is seeking a Senior Big Data Engineer. As the Senior Big Data Engineer, you will be responsible for the design and development of RF-DS platform in Enterprise Risk Technology. It will be a hands-on platform support role on Hadoop stack, leveraging technologies such as but not limited to Hive, Spark, Scala, Impala, Flume, Oozie, Tez, Ranger, SOLR, HBase, and other open-source projects. Skills - 4+ years of building and deploying enterprise large scale big data clusters Proficiency in administrating Big Data technologies (Hadoop, HDFS, Spark, Hive, Yarn, Oozie, Kafka, Hbase, Apache stack) Hadoop is a must. Proficiency in defining highly scalable Platform Architecture. Architectural Design Patterns, highly optimized, Low latency and Massively Scalable Platforms If this role is of an interest, please apply! Morgan McKinley is acting as an Employment Agency and references to pay rates are indicative. BY APPLYING FOR THIS ROLE YOU ARE AGREEING TO OUR TERMS OF SERVICE WHICH TOGETHER WITH OUR PRIVACY STATEMENT GOVERN YOUR USE OF MORGAN MCKINLEY SERVICES."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=dec3e14a8a8af921", "page": 1, "job_title": "Data Engineer", "company_name": "Future Work", "job_location": "Surrey", "job_type": "Permanent", "jobkey": "dec3e14a8a8af921", "date_posted": "5 days ago", "jobDescription": " Description Are you passionate about data engineering and ready to take on exciting challenges in the world of artificial intelligence? An international AI consultancy, delivering cutting-edge AI solutions that has a growing team of experts combining their skills in data science, machine learning, and engineering to create innovative and impactful solutions to clients worldwide. As a Data Engineer, you will play a key role in designing and building robust data infrastructure and pipelines to support our AI projects. As a Data Engineer you will collaborate closely with our talented team of data scientists, machine learning engineers, and cross-functional teams to develop efficient data solutions. Your responsibilities will include designing and optimizing data pipelines, implementing data governance and security measures, and ensuring the seamless integration of structured and unstructured data from various sources. You will work on exciting projects, leveraging technologies such as Apache Spark, AWS, and SQL databases, while staying at the forefront of industry trends and emerging technologies. To succeed in this role, you will be educated to degree level in computer science, engineering, or a related field. You will possess a strong programming background, with expertise in Python, Java, or Scala. Experience with big data frameworks such as Apache Hadoop or Apache Spark is essential, as is familiarity with relational and NoSQL databases. Knowledge of cloud platforms like AWS, Azure, or GCP and their data services is highly desirable. Excellent problem-solving skills, a passion for innovation, and effective communication abilities are also key to excelling in this position. In return, the company offers the opportunity to work with a cutting-edge scale-up growing quickly and the winner of multiple international awards with lots of scope for growth. You will work with a large group of technology professionals who are building cutting-edge AI for the world, in a great environment of energetic, fun-loving and interesting people who love to explore. If you are a motivated and results-oriented individual with a passion for technology and then we want to hear from you. Data Engineer Permanent Surrey £90000 - £130000 548754 "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=4c8ebae19d90a419", "page": 1, "job_title": "Data Engineer", "company_name": "Explore Group", "job_location": "London", "job_type": null, "jobkey": "4c8ebae19d90a419", "date_posted": "3 days ago", "jobDescription": "Data Engineer - Outside IR35 Contract Explore Group are partnered with an exciting business who are looking to engage with two Data Engineers on a contract basis. You will be working in a close-knit, and cross-functional team consisting of backend and frontend engineers - spearheaded by the CTO and CPO. You will need to have strong experience with the below: AWS Stack Python Redshift DBT Cube ASAP Start, interview slots confirmed for Monday 19th June &amp; Tueday 20th June. Reach out to me: reuben.adebambo@exploreltd.com or apply directly!"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=1503566e64deedb6", "page": 1, "job_title": "Senior Data Engineer", "company_name": "NewDay", "job_location": "London", "job_type": "Full-time, Permanent", "jobkey": "1503566e64deedb6", "date_posted": "1 day ago", "jobDescription": " Permanent Full Time role in Data Architecture &amp; Data Engineering. Located in London - Hybrid. Permanent Full Time Data Architecture &amp; Data Engineering London - Hybrid Senior Data Engineer Your new role At NewDay This position needs someone with energy and passion to complement our existing development team, to contribute to our existing projects as well as work on strategic new projects. In this role you must have a desire to deliver high quality output within challenging timeline. The ability to hit the deck running and make valuable contributions quickly will be critical. 0-12 months you’ll deliver Hands on development on Nexus Platform Responsible for the code quality and simplicity in the system Working with the team of data engineers and data designers within an Agile framework Building knowledge of all data resources within ND and prototype new data sources internally and externally What you’ll bring We need knowledge, experience + expertise in: Proficiency in technologies such as Spark (SQL and/or Scala), Kafka. Experience in Scala programming language Analytical and problem-solving skills, applied to data solution Proficiency with traditional database SQL technologies Experience with integration of data from multiple data sources Experience of CI/CD best practices And would love you to know or learn: Experience of ETL technologies AWS exposure (Athena, Glue, EMR, Step functions) Experience of relational database technologies (MS SQL Server, Redshift, Aurora) Experience with data solution BAU processes (ETL, table refresh etc About NewDay We help people move forward with credit, and help our colleagues to move their careers forward too. We use our highly flexible, scalable, and multi-product digital credit engine to power over 120 million transactions every year. Our brands include Aqua, marbles, fluid and Bip. We partner with leading brands such as John Lewis, AO, Argos and DEKO. Over 5 million UK customers are supported by our award-winning customer service. At NewDay, we value all types of diversity. We’re an equal opportunity employer and believe that our differences create a vibrant, authentic working culture. We want all our colleagues to feel able to bring their whole selves to work. We don’t discriminate on the basis of age, physical or mental disability, gender reassignment, marriage and civil partnership, pregnancy and carer status, race (including colour, nationality, and ethnic or national origin), religion or belief, sex and sexual orientation. We make sure that every job is crafted to be inclusive and that people with disabilities or caring responsibilities can take part in the application and interview process. Tell us if you need accommodations: we’ll put reasonable adjustments in place to support you. Our dynamic NewDay culture We’re focused on what will drive impact in helping people move forward with credit. Our distinctive culture is geared to spark innovation and team working – with lots of open doors for development. Our customers can rely on us because we aim high, support each other, do the right thing and build for the future. We invest in our colleagues. On top of a strong market competitive salary, you get a bonus opportunity that matches the impact (delivery + values) you drive in your role. We also help you retire better with market leading pensions. At NewDay, #yourwellbeing matters: You get 26 days holiday and can buy up to 5 more after probation. Then you’ll get extra days as you build your career with us. NewWork, our flexible, hybrid working approach, helps you to manage your work/life balance - and even bolt on work time in other countries before or after your holiday. And when you’re in the office, you get free healthy breakfast, fresh juices, lunch, barista coffee etc Our tax efficient green car and cycle to work schemes save you money (and help the planet). Ask your Talent Acquisition Partner to tell you more about any of our perks. Where next? In the NewDay Tech team, you’ll join an Expert or Leader career pathway. This will guide you on what your next step here could look like, with regular and open feedback to help you build capabilities to move forward. We work with Textio to make our job design and hiring inclusive Let’s talk about this role – contact talent@newday.co.uk "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=7240d675f186231d", "page": 1, "job_title": "Senior Data Engineer", "company_name": "Allied World Assurance Company", "job_location": "London", "job_type": null, "jobkey": "7240d675f186231d", "date_posted": "2 days ago", "jobDescription": " Senior Data Engineer - Global IT Group - ( 2300003V ) Description Company Overview: Allied World is an established insurance company specializing in providing a range of Property and Casualty insurance products to customers. We are currently seeking a highly skilled Data Engineer to join our team and play a key role in designing and implementing a data platform for our pricing actuaries. Job Summary: As a Data Engineer, you will be responsible for assisting in gathering requirements, designing a scalable and efficient data platform, and leading a third-party team to build and deploy the system. The platform will need to support an array of highly specific domains, each represented in its fullest detail, but tied together to be meaningful in the aggregate. Additionally, you will support and maintain existing systems built in SQL Server and investigate data anomalies alongside the business with minimal handover. Your primary focus will be on designing data models and pipelines, integrating data from various sources, ensuring data quality and reliability, and providing technical leadership. Job Duties: 1. Gather and analyse requirements: Collaborate with pricing actuaries, data analysts, and other stakeholders to understand their data needs and requirements. Identify and document data sources, data integration requirements, and data transformation processes. 2. Design a scalable data platform: Architect and design a robust and scalable data platform that meets the requirements of pricing actuaries. Determine the appropriate technologies, tools, and frameworks for data integration, storage, and processing. Ensure data security, privacy, and compliance standards are met. 3. Implement data pipelines and integrations: Develop and maintain data pipelines to extract, transform, and load (ETL) data from various sources into the data platform. Integrate external data sources, APIs, and third-party systems with the data platform. Implement data validation and quality checks to ensure accuracy and reliability. 4. Support existing systems and investigate data anomalies: Maintain and support existing systems built in SQL Server. Investigate data anomalies reported by the business, proactively identifying and resolving issues. Conduct root cause analysis and implement corrective measures. 5. Lead third-party team: Collaborate with external vendors or third-party development teams to build and deploy the data system. Provide technical guidance, support, and oversight to the third-party team. Ensure timely delivery of milestones and adherence to project timelines. 6. Optimize performance and scalability: Identify and implement performance optimizations to ensure efficient data processing and storage. Monitor and troubleshoot issues related to data pipelines, data quality, and system performance. Continuously evaluate and recommend improvements to the data system architecture and processes. Qualifications Job Requirements: Bachelor’s degree in computer science, Engineering, or a related field. A Master's degree is a plus. Proven experience working as a Data Engineer or a similar role in designing and implementing data systems. Strong understanding of data engineering principles, data modeling, ETL processes, and data integration techniques. Proficient in programming languages such as SQL, Python, and experience with relevant data processing frameworks (e.g., Apache Spark, Hadoop). Experience with cloud platforms (e.g., Azure, AWS) and familiarity with relevant services (e.g., Data Factory, Azure Blob Storage, Glue, S3). Strong expertise in SQL Server, including performance optimization, query tuning, and troubleshooting. Knowledge of data governance, security, and privacy best practices. Excellent problem-solving and analytical skills, with the ability to translate business requirements into technical solutions. Strong communication and interpersonal skills to collaborate effectively with stakeholders and third-party teams. Curiosity and a willingness to learn and support existing systems built in SQL Server. Ability to investigate data anomalies with minimal handover and provide timely resolutions. Primary Location : GB-GB-London Work Locations : London 20 Fenchurch Street London EC3M 3BY Job : Information Technology Employee Status :Regular Job Type :Experienced Job Posting : Jun 20, 2023, 2:57:01 AM Pay BasisYearly "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=9d8850d428a799a4", "page": 1, "job_title": "Senior Data Engineer", "company_name": "Xcede", "job_location": "London", "job_type": "Permanent", "jobkey": "9d8850d428a799a4", "date_posted": "6 days ago", "jobDescription": " Posted:6 days ago Sector: Data, Data Engineering Location: London Job Ref: PR/118919_1686845278 Job Type: Permanent Salary: £80000 - £120000 per annum per year Expiry Date: 25 July 2023 Contact: Nathan Carolan Contact Email: nathan.carolan@xcede.com Job Description Senior Data Engineer Global Software Scale-Up London (hybrid) £80,000 - £120,000 + Stock Xcede is excited to be partnered with a Global Software Scale-Up organisation who are revolutionising their field. The organisation can hire at Data Engineer level through to Principal Data Engineer level. This is an exciting role for a well established Data Engineer who wants to join a high performing team in an organisation who are trying to push the boundaries. You will be responsible for rebuilding the organisations current ETL tool/platform. Key skills/experience required: BSc/MSc in a STEM subject 4 - 8 years' experience in building data pipelines and data lakes within the cloud Extensive Python experience required + other languages are nice to gave (e.g. Go) Strong Software Engineering best practice principles Understanding of datawarehouses such as Snowflake and Reporting tools such as Looker Good understanding of software design patterns and architecture Extensive SQL tuning skills Solid experience with Kubernetes, Docker, CI/CD is nice to have For more information, please send an up-to-date CV to nathan.carolan@xcede.com Data Engineering, Data Pipelines, Data Lakes, Datawarehouse, ETL, Cloud, AWS, GCP, Python, SQL Software Engineering, Docker, Kubernetes, CI/CD "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=0f9df7943c40daa7", "page": 1, "job_title": "Data Engineer - Hybrid - Guildford, London or Gloucester", "company_name": "BAE Systems Applied Intelligence", "job_location": "London", "job_type": "Full-time", "jobkey": "0f9df7943c40daa7", "date_posted": "1 day ago", "jobDescription": " Location(s): [[mfield3]] BAE Systems Digital Intelligence is home to 4,500 digital, cyber and intelligence experts. We work collaboratively across 10 countries to collect, connect and understand complex data, so that governments, nation states, armed forces and commercial businesses can unlock digital advantage in the most demanding environments. Data Engineer – Hybrid - Guildford, London or Gloucester We are looking for an experienced Data Engineer to join our growing NNCC project. You will get to use cutting edge tech to research, prototype, develop and engineer complex analytics, on incredibly large datasets. This role offers an excellent opportunity to work in a fast paced growing area of BAE Systems Digital Intelligence. The team: This role is within the behavioural analytics team of the NNCC (National Network Cyber Centre) project. NNCC is a product sold internationally with the goal of identifying malicious behaviour from advanced threats in network traffic. It is a country level cyber solution and operates at the speed and scale of the national Internet. Using cutting-edge technology, the behavioural analytics team research, prototype, develop and engineer complex analytics, on incredibly large datasets, to identify anomalies, and detect and correlate threats across the cyber kill chain. The analytics team works as both a long-term development team for the core NNCC product, as well as a data lab focussed research team for specific clients. They rapidly spin-up prototypes to serve immediate operational needs. The role: To design, implement and test scalable and performant analytic pipelines - with guidance from a Data Scientist and Solution Architect. To contribute to the continuous improvement of the engineering processes and architecture for the analytics solution. To detect and analyse performance bottlenecks in new and existing solutions. To tune analytic implementations to cope with the solution scale – we ingest millions of events per second. To communicate and act on solution improvement ideas. To rapidly learn new technologies. Your experience: Experience in the following is essential: Python, our code base is Python based Understanding of how to write and test performant code to handle data at scale / big data volumes using Spark / PySpark Knowledge of the following big data technologies would be extremely advantageous: HDFS (forms our persistence backbone) HBase / Elasticsearch databases (used to store entity data) Kafka(for messaging / subsystem buffering) Knowledge of all or some of the following would be a bonus: Ansible (our solutions are installed using Ansible) Airflow/ Jupyter (for job control and one off tasks) A JVM language e.g. Java / Scala Unix shell scripting (BASH for example) Data formats such as Parquet and Avro How we will support you: Work-life balance is important; you’ll get 25 days holiday a year and, via our flexible benefits package the option to buy/sell and carry over from the year before Our flexible benefits package includes; private medical and dental insurance, a competitive pension scheme, cycle to work scheme, taste cards and more You’ll have a dedicated Career Manager to help you develop your career and guide you on your journey through BAE Don’t know a particular technology? Your learning and development is key to your future career You’ll be part of our bonus scheme You are welcome to join any/all of our Diversity and Support groups. These groups cover everything from gender diversity to mental health and well being. Security Clearance Only those with the permanent and unrestricted right to live and work in the UK will be considered. Due to the nature of our work, successful candidates for this role will be required to go through Government security clearance prior to starting with us. https://www.gov.uk/guidance/security-vetting-and-clearance Life at BAE Systems Digital Intelligence We are embracing Hybrid Working. This means you and your colleagues may be working in different locations, such as from home, another BAE Systems office or client site, some or all of the time, and work might be going on at different times of the day. By embracing technology, we can interact, collaborate and create together, even when we’re working remotely from one another. Hybrid Working allows for increased flexibility in when and where we work, helping us to balance our work and personal life more effectively, and enhance well-being. Diversity and inclusion are integral to the success of BAE Systems Digital Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=a686a368ddac4f9f", "page": 1, "job_title": "Data Engineer", "company_name": "Global Radio Services", "job_location": "London", "job_type": "Full-time", "jobkey": "a686a368ddac4f9f", "date_posted": "1 day ago", "jobDescription": " Job Description Data Engineer Reporting of the role This role reports to Head of Data Engineering Overview of job We are looking for a passionate Data Engineer with excellent problem solving, teamwork, and communication skills to join our dynamic data team based in London. The role would be reporting to the Head of Data, and focused initially on DAX - a groundbreaking digital advertising exchange which connects brands with audiences at scale across connected audio and digital out-of-home. This role will be responsible for building and evolving key DAX data services such as publisher/advertiser insights, identity resolution and audience modelling. This is a phenomenal opportunity to use and develop your technical expertise to work alongside a very successful project within Global, and to deliver ground-breaking and innovative data products that will impact audio and out-of-home ad-technology. 3 best things about the job Play a central role in crafting and defining our data architecture at a pivotal time for data strategy in Global! Work with a team of data and software specialists, passionate about building scalable data services and pushing towards turning DAX into an efficient ad delivery platform that feeds from real-time data insights! Getting training and hands-on experience on the latest tools and technologies such as AWS, Apache Spark, K8s, etc. Measures of success – In the first few months, you would have: Applied sound standard methodology in deploying data services; appreciating potential impact to scalability, reliability, accuracy, efficiency and costs Shown understanding of how and why data services are applied in programmatic advertisement Contributed to the development of our streaming data pipelines. Become immersed within ad technology and programmatic advertisement; partnering with the business to deliver trusted data products. Responsibilities of the role Building and evolving key data platforms, services and pipelines used across DAX Being responsible for the development of streaming systems and Big Data management Be accountable for delivering data services that produce tangible business value Maintaining existing pipelines and processes, such as Airflow DAGs of varied types, guaranteeing continuous data delivery What will you need The ideal candidate will be proactive and willing to develop and implement innovative solutions, capable of the following: Recommended: Skilled in a programming language (Python, Java, etc.) Proficiency with cloud services (ideally AWS) Large-scale streaming data (Apache Kafka, etc.) Experience with low-latency time-series database (Apache Druid) Understanding of building and deploying highly available, distributed systems of data extraction, transformation and loading of datasets Monitoring data reliability and infrastructure performance Knowledge of continuous delivery and continuous integration (Jenkins, Docker, K8s) Understanding of Agile methodologies and Continuous Delivery Bonus Points for: Databricks/Apache Spark AWS/Azure/GCP Certifications Infrastructure as Code (i.e. Terraform) Ability to debug distributed architecture Everyone is welcome at Global Just like our media and entertainment platforms are for everyone, so are our workplaces. We know that we can’t possibly serve our diverse audiences without first nurturing and celebrating it in our people and that’s why we work hard to create an inclusive culture for everyone. We believe that different will set us apart, so no matter what you look like, where you come from or what your favourite radio station is, we want to hear from you. Although we cannot make guarantees, we welcome conversations about flexible working for all roles at Global"},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=61ac409dcfc0e905", "page": 1, "job_title": "Data Engineer", "company_name": "BeZero Carbon", "job_location": "London EC1Y", "job_type": "Full-time", "jobkey": "61ac409dcfc0e905", "date_posted": "Today", "jobDescription": " Data Engineer Full time, London or UK-based. About us: BeZero Carbon is a global ratings agency for the Voluntary Carbon Market. Our ratings allow all market participants to price and manage risk. BeZero’s ratings and research tools support buyers, intermediaries, investors, and carbon project developers. Founded in April 2020, our 120-strong team combines climatic and earth sciences, sell-side financial research, earth observation, machine learning, data and technology, engineering, and public policy expertise. We work from five continents. www.bezerocarbon.com Background on the role: BeZero is seeking a mid-level data engineer to join our data engineering team. The team is responsible for building and deploying data and machine learning products for our client-facing platform and internal teams. The team sits at the heart of the business, working across our ratings, product, and technology teams. As a data team, we have a bias towards shipping products, staying close to our internal and external customers, end-to-end ownership of our infrastructure and deployments. This is a team that follows software engineering best practices closely. Our data stack includes the following technologies: AWS serves as our cloud infrastructure provider. Snowflake acts as our central data warehouse for tabular data. AWS S3 is used for any of our raster data, and we use PostGIS for querying geospatial vector data. We use dbt for building SQL-style data models and Python jobs for non-SQL data transformations. Prefect as our workflow orchestration manager, and our jobs are executed on AWS ECS. AWS Sagemaker acts as a platform for data science and research teams to develop models. Metabase serves as a dashboarding solution for end-users. GitHub Actions is our chosen CI / CD tool. In this role, you will contribute to the development of data products and algorithms that directly impact how our ratings team analyzes carbon offset projects. You will work with various types of data, including: Processing large volumes of geospatial raster and vector data to create data products that quantify factors like fire risk, drought risk, deforestation rates, carbon stocks, and other metrics relevant to carbon offset projects. Utilizing natural language processing techniques to extract data points from carbon offset project documents, which are essential inputs for our ratings process. Working with structured data on carbon offset projects and accreditation bodies, providing insights for our research on carbon market and policy trends. Although we work across all these different areas, this role will have a strong emphasis on working with geospatial raster and vector data. While previous experience in this domain is a strong bonus, it is not a must-have for us, and we are able to train you in the geospatial data domain. We are a remote-friendly company; however, for this position, we will only consider applications from candidates based in the UK. If you are located in or near London, you are welcome to work from our London office. Responsibilities: You will be an individual contributor in our geospatial data team, focused on developing and maintaining and maintaining geospatial data products to be deployed on our carbon markets platform or used internally by our ratings team. You will build automated data pipelines to collect and manipulate large geospatial data sets, including optical satellite imagery, SAR and LiDAR data, climate data, and others. You will work with our internal research and ratings teams to integrate the outputs of (analytical) data pipelines into BeZero’s business processes. You’ll be our ideal candidate if: You care deeply about the climate and carbon markets and are excited by solutions for decarbonising our economy. You are a highly collaborative individual who wants to solve problems that drive business value. You have at least 2 years of experience building ELT pipelines in production for data engineering or machine learning use cases, using Python and SQL. You have hands-on experience with workflow orchestration tools (e.g., Prefect, Dagster, Airflow, Luigi), containerization, a cloud platform (we use AWS but any cloud platform will do) and the Python scientific computing stack (NumPy, SciPy, matplotlib, pandas, etc). You can write clean, maintainable, scalable, and robust code in Python and SQL, and familiar with collaborative coding best practices (e.g., for Python PEP8 code style, unit testing, continuous integration tools such as flake8, black, isort, etc). You are well-versed in code version control and have experience working in team setups on production code repositories. Bonus points (but we’d still like to hear from you if you don’t have experience in any of these) You have experience dealing with a variety of geospatial data formats (e.g., netCDF, (cloud-optimised) geotiff, geoJSONs, zarr) and geospatial SQL and Python packages (e.g., PostGIS, xarray, rasterio, shapely, gdal). You have experience in deploying cloud resources using tools such as AWS Cloud Formation, Terraform, etc. You have experience in productionising and analysing specific satellite imagery data types like SAR, LiDAR, or RADAR or another remote sensing domain. Research has shown that women are less likely than men to apply for a role if they don’t have experience in 100% of the requirements outlined in a job description. Please know that even if you don’t have experience in all the areas above but think you could do a great job and are excited about shaping company culture, finding great people, and building great teams, we’d love to hear from you! What we’ll offer: Competitive salary and opportunity for equity in a rapidly growing VC-backed start-up through share options Ability to learn and develop alongside a range of sector specialists from the scientific, economic and business community Opportunity to work in a cross-cutting role, interacting with lots of different parts of the business Growth opportunities that come from working at a fast-paced VC-backed technology business Opportunity to work remote or in our Central London office space (Old Street) with flexibility to work from home + some flexibility over working location during the summer Regular social events 25 days leave (with additional time off between Christmas and New Year, and for your birthday) Private medical insurance, dental, critical illness cover, income protection, life assurance, medical cash plan, cycle to work scheme, and a health and wellness cash allowance Our interview process: Initial screening interview with recruiter (15 mins) Introduction call with Chief Data Strategist (30 mins) 2x Technical interview with members from the data engineering &amp; science team (60-90 mins) Reference checks + offer We value diversity at BeZero Carbon. We need a team that brings different perspectives and backgrounds together to build the tools needed to make the voluntary carbon market transparent. We’re therefore committed to not discriminate based on race, religion, colour, national origin, sex, sexual orientation, gender identity, marital status, veteran status, age, or disability."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=04635f8d6f584adf", "page": 1, "job_title": "Senior Data Engineer", "company_name": "JPMorgan Chase Bank, N.A.", "job_location": "London", "job_type": "Full-time, Permanent", "jobkey": "04635f8d6f584adf", "date_posted": "Today", "jobDescription": ". J.P. Morgan is a global leader in financial services, providing strategic advice and products to the world's most prominent corporations, governments, wealthy individuals and institutional investors. Our first-class business in a first-class way approach to serving clients drives everything we do. We strive to build trusted, long-term partnerships to help our clients achieve their business objectives. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=7a444ceccad69825", "page": 1, "job_title": "Data Engineer", "company_name": "Heathrow", "job_location": "London", "job_type": "Full-time", "jobkey": "7a444ceccad69825", "date_posted": "5 days ago", "jobDescription": " Heathrow is a city within a city, through which millions of passengers travel every year. In Operational Planning, our goal is to give passengers the best airport service in the world , in an environment where change is constant. Join us and you’ll become part of an exciting and fast-paced team that keeps the airport running smoothly. Whether it's using data and strategy to predict and plan for events, responding to unexpected disruptions, or working closely with Airport Operations Control and airlines to optimise flight schedules and reduce delays, you’ll make a real difference to the experience of countless passengers. Together, we’re responsible for creating the right planning proposition, from defining roles to building rosters, and delivering an effective plan every day. It’s about understanding our capacity and making best use of it. And about evaluating our performance every day, so we can continuously improve. Every day will test your skills and give you the opportunity to make your mark at one of the busiest airports in the world . Join us and discover a one-of-a-kind career. Working within our Operations Planning Team, the Data Analytics Engineer will be instrumental in leading, shaping projects end to end. The team are analytical, technical, process and people focused that thrive on working with data. You will have the opportunity to apply your knowledge but at the same time learn. This role would suit candidates that want to develop their career as part of a team of highly skilled professionals who are passionate about increasing the value of the data and analytics in organisation If you’re looking for a role where empowerment, collaboration and a solutions focus is important this could be a great role for you! As the Data Engineer, you will work closely with the stakeholders to define the requirements of a project and then build solutions. You will be expected to demonstrate certain skills in order to successfully fulfill the role. These include: Assemble large, complex data sets to meet functional/non-functional business requirements and deliverables Identify, design, and implement internal process improvements to optimise data delivery, data governance inc. lineage, catalogue and quality Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Data Warehousing, R and Cloud technologies Work with software engineering best practices such as version control, continuous integration and test-driven development including Azure Dev Ops Work with MS Azure including Databricks, Data Factory, Dev Ops, REST API,, ADLS, Azure Synapse, Blob Storage and Power BI Datasets Use of advanced SQL skills and an understanding of query and storage optimization As well as the technical requirements listed below, we are looking for candidates that enjoy stakeholder relationships and can work cross functionally. Azure knowledge and experience working with relational databases (Azure Data Factory, Azure DevOps) Working experience with version control platforms, ideally through Azure DevOps Experience with business intelligence tools, ideally Power BI (including Dax and M) Experience in gathering and analysing system requirements Strong in data governance, including Master Data Management (MDM) and Data Quality tools and processes Ideally a Computer Science, Statistics, Business Analytics, or Mathematics Heathrow brings the world closer together. Our airport facilitates the global travel and trade that keeps the economy moving. It’s a place like no other – a city within a city – where colleagues connect around a common goal, giving our passengers the best airport service in the world. There is a world of opportunity at Heathrow. You’ll reach your full potential within our inclusive and supportive culture, whilst helping us to deliver our ambitious plans. Not only are we growing to welcome millions more passengers each year, we’re also transforming our industry. Sustainability is at the heart of Heathrow and we’re leading global efforts on decarbonisation, so that aviation continues to be a force for good in our world. Taking the journey with us means living our values. Doing the right thing. Keeping everyone safe. Working together. Treating everyone with respect. Giving excellent service. Improving every day. Our ever-changing airport runs on teamwork and creativity. A career at Heathrow is welcoming, diverse, challenging, exciting, and rewarding. Join Heathrow and grow your career in an airport that matters to millions. Our rewards We offer competitive salaries and excellent benefits, along with performance-based annual bonuses, our longer-term Share in Success Bonus plans, generous annual leave allowances and market-leading pensions. With family friendly policies, access to private health insurance and a wide range of wellbeing tools, we’ll support you to be at your best inside and outside work. And we’ll provide learning and development opportunities to help you reach your full potential. Working location This is an airport-based position. Every day, you will play a critical role in helping us to give our passengers the best airport service in the world. Sustainable Travel to work Heathrow’s Sustainable Travel Guide sets out easy and sustainable travel options that everyone can access. Equal Opportunities As an equal opportunities employer, we encourage applications from all. We believe that diverse talent makes us stronger – not least because we welcome passengers from all corners of the globe, every single day. Heathrow is an accessible place to work. With four diversity networks, we champion inclusivity and celebrate individuality."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=825efb485c4725da", "page": 1, "job_title": "Data Engineer", "company_name": "Onmo", "job_location": "London EC4M", "job_type": null, "jobkey": "825efb485c4725da", "date_posted": "5 days ago", "jobDescription": " WHO ARE WE? Onmo is looking for a talented, organised and detail-oriented Data Engineer to join our growing technology team. Onmo is on a quest to be the world’s most proactive bank. We improve lives by providing better clarity, intelligence and technology to empower every individual in making the smartest financial decisions. Our product is developing with incredible pace; we are already at the point where we must enhance features, improve the customer experience and focus on creative crafting that we sidestepped in the drive to launch our app and MVP website. So, it’s time to take a step back, improve what we have created and realise our plan to create world-class, intuitive and beautiful products that are a joy to use. This is where you come in. We are seeking a talented data engineer with expertise in AWS, S3, Databricks, and Python to join our growing team. The successful candidate will be responsible for building and maintaining data pipelines, optimising data delivery, and designing and implementing data storage solutions. This role will require strong technical skills in cloud-based data engineering, data modelling, and data architecture, as well as experience with Python programming. WHAT WILL YOU BE DOING? Design, build and maintain scalable and efficient data pipelines and storage solutions on AWS using S3, Databricks and other relevant technologies. Work with cross-functional teams to identify and prioritise data engineering needs and develop solutions that meet business requirements. Optimise data delivery and processing, ensuring data quality and consistency across multiple sources. Develop and maintain data models and schema designs that support data warehousing, analytics and reporting. Collaborate with data scientists and analysts to enable data-driven decision making, providing support and guidance on data engineering best practices. Implement and maintain data security protocols, ensuring data privacy and compliance with regulatory standards. WHAT ARE WE LOOKING FOR? Requirements At least 3 years of experience in data engineering, with a focus on cloud-based solutions using AWS, S3 and Databricks Strong programming skills in Python, with experience in building and deploying production-grade applications. Strong understanding of data warehousing, ETL processes, and data modelling concepts. Experience with distributed data processing frameworks such as Apache Spark Excellent problem-solving skills and attention to detail, with the ability to work independently and as part of a team. A LITTLE ABOUT YOU! Excellent communication skills, with the ability to explain and present detailed concepts or requirements clearly, tactfully and concisely to what may not always be a technically experienced audience – in person and in writing. Self-motivated, can be relied upon to follow up questions and outstanding actions, and to drive projects to completion according to requirements and schedules. You can see opportunities to explore new approaches and are not scared by the unpaved road ahead. Onmo is a start-up environment, and we need help to create the culture, processes and standards which drive our future behaviour. Excited by world-class creative and fresh thinking; able to translate ideas into practical concepts and clear briefs. WHAT IS IN IT FOR YOU? Be part of something! This is a rare opportunity to join a consumer-driven business in its infancy, bringing to market a suite of exciting new products. As our funding is secure, this is the best of start-up environments. Be part of a small, motivated and specialised team who look out for one another and with a giant shared ambition, enjoy a collegiate spirit. You will enjoy access to the entire business, gaining a wealth of experience from colleagues with a raft of skillsets and start-up experience. Birthdays off. Personal days/charity/volunteering days. Buy and sell holidays (up to five days). Social calendar. Cycle to Work and Season Ticket Loan schemes. Personal training budget. Free drinks fridge and snacks. "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=7ef85f0bf794b8a6", "page": 1, "job_title": "Data Engineer", "company_name": "JPMorgan Chase Bank, N.A.", "job_location": "London", "job_type": "Full-time, Permanent", "jobkey": "7ef85f0bf794b8a6", "date_posted": "3 days ago", "jobDescription": "Project Description We are not your standard bank, we are a house of innovation! We are part of the team that launched Chase as a new UK bank in 2021, and are now building a new team in a new department with even bigger ambitions. More details will be provided during the interview but for now we can enthusiastically say: It's challenging, it's high stakes, it's fun! Our team is at the heart of building this new venture, focused on developing products that put the customer at the centre. We have created a new organisation with diverse professionals that come from a wide set of skills, backgrounds and experiences, including b2b and b2c businesses. We want people that are exceptional at what they do. Culture Team members have broad autonomy to collaborate and work in a cross-functional way and we value your opinion in every matter; so if you are a Software Engineer and you want to get involved in Infrastructure - please do! Or a Designer and want to help with user testing - go for it! Teams own their work end-to-end and we have a flat organisational structure. We are about bringing new products to market that solve real world problems for real life customers, not just innovation for the sake of innovation. Our inclusive culture is hugely important to us and we are looking for intellectually curious, compassionate people who would like to expand their skills whilst working on a new exciting venture for the firm. We are human first; we love working with each other, and we need personal connections and in-person bonding. We find we are happier, more motivated and more productive this way. If this sounds like something that you would like to be a part of we'd encourage you to read on and apply, even if the job description isn't an exact match for you, we can promise to review your application and let you know if there is anything that might be suitable in the future! Mission Act as a data specialist, putting your expertise to the service of your team, to delight our customers in a way that is viable for the business. Be part of the solution which stewards and handles the data, so that it remains a strategic asset and a competitive advantage. Key Outcomes Set data management and lifecycle standards and provide tools for customers to make it easy to follow them (documentation, change management). Advise and collaborate with your customers (other teams) so they can collect and query data according to the requirements (latency, response time, etc.) in a consistent way with the ecosystem. Design, implement, maintain or help to maintain (depending on the setup) the components necessary to provide data services for customers. Provide and maintain necessary tooling for customers (documentation, utilities, libraries, etc.). Promote standard, consistent solutions over tactical ones, favour long-term solutions. Follow various legal data management frameworks (e.g. GDPR, CCPA, etc.) and provide tooling and help for the customers to be compliant - please note that the role is not about being responsible for enforcing the legal rules on the teams or to understand the legal text. Feel responsible to make sure the sensitive data is attributed and handled properly and help data producing/consuming teams to be compliant. Be ready to understand the data to and the use-cases around it to spot synergies. Be curious and keep up-to-date with new data-related solutions, products, come up with new proposals to improve our ecosystem. Core Competencies Ownership. Identifies problems, proposes solutions, suggests what's best to focus on. Sees themselves as a problem solver. Contributes to the problem at hand, even when outside their area of speciality. Collaboration. Loves working within a co-located team. Enjoys pairing and mobbing programming. Doesn't compete with peers. Shares their knowledge and understanding with everybody. Adaptability. Adjusts quickly to changing priorities and conditions. Copes effectively with complexity and change. Learns and unlearns technologies and patterns quickly. Comfortable in uncharted waters. Long-term thinking. Doesn't sacrifice the future for the present. Chooses technologies and approaches based on the end goals. High standards. Expects personal performance and team performance to be nothing short of the best. Hires A Players. Never stops learning. Integrity. Does not cut corners ethically. Earns trust and maintain confidences. Does what is right, not just what is politically expedient. Speaks plainly and truthfully. Doesn't play games. Does what's best for the company, rather than what's best for themselves or their team. Technologies Our tech stack is in very early stages, and we want people like yourself to help us forming and evolving it. At the moment it looks like: Back-End: Kotlin, Gradle, Micronaut, Apache Pulsar, Docker Front-End: Typescript, React, Jest, Vite, Node, Docker, Mobx, Nx Infrastructure: GCP, AWS, Azure, Kubernetes, GoLang, Pulumi, Service Mesh CI/CD: GitHub, GitHub Actions, ArgoCD What we expect from you Experience with JVM-based languages like Java, Kotlin or Scala. Either experience with Big Data frameworks e.g. Spark, Flink, Storm, Samza, Beam etc. or experience with event brokers like Kafka or Pulsar. Good understanding of data structures. Good understanding of concurrency and concurrency primitives. Interest in Big Data and building data pipelines, being in this role in the past is not a must. Nice to have Experience with a project which consisted at least a few independently deployed SW components (not necessarily microservices) and having been involved throughout the whole SW lifecycle (of some components). Experience with Kubernetes. Experience working with cloud platform(s), e.g. AWS or GCP. Why It's Awesome This is an incredibly ambitious project, run with unconventional degrees of autonomy. It's a greenfield initiative, and we haven't done anything yet, so you can have a big impact from the start. The quality of our team will determine the outcomes of the project, so we're committed to get the best people around. You can expect to form long-lived relationships with crazy smart folks here. The way we work is truly lower-case agile. Not talking about it. Not having meetings about it. Actually doing it. Test Driven Development, Domain Driven Design, work on trunk, mob and pair programming, work queues, work in progress limits, cross-functional teams, continuous integration, continuous delivery, continuous deployment. J.P. Morgan is a global leader in financial services, providing strategic advice and products to the world's most prominent corporations, governments, wealthy individuals and institutional investors. Our first-class business in a first-class way approach to serving clients drives everything we do. We strive to build trusted, long-term partnerships to help our clients achieve their business objectives. We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=a53839b0a678e855", "page": 1, "job_title": "Data Engineer", "company_name": "NBCUniversal", "job_location": "Brentford", "job_type": "Full-time", "jobkey": "a53839b0a678e855", "date_posted": "Today", "jobDescription": " Company Description We create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations &amp; Experiences. NBCUniversal is a subsidiary of Comcast Corporation. Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world. Job Description Our Direct-to-Consumer (DTC) portfolio is a powerhouse collection of consumer-first brands, supported by media industry leaders, Comcast, NBCUniversal, and Sky. When you join our team, you’ll work across our dynamic portfolio including Peacock, NOW, Fandango, SkyShowtime, Showmax, and TV Everywhere, powering streaming across more than 70 countries globally. And the evolution doesn’t stop there. With an unequaled scale, our teams make the most out of every opportunity to collaborate and learn from one another. We’re always looking for ways to innovate faster, accelerate our growth, and consistently offer the very best in the consumer experience. But most of all, we’re backed by a culture of respect. We embrace authenticity and inspire people to thrive. As part of the Direct-to-Consumer Decision Sciences team, the Data Engineer will be responsible for creating a connected data ecosystem that unleashes the power of our streaming data with a focus on international propositions. We gather data from across all customer/prospect journeys in near real-time, to allow fast feedback loops across territories; combined with our strategic data platform, this data ecosystem is at the core of being able to make intelligent customer and business decisions. In this role, the Data Engineer will share responsibilities in the development and maintenance of optimized and highly available data pipelines that facilitate deeper analysis and reporting by the business, as well as support ongoing operations related to the Direct-to-Consumer data ecosystem. Responsibilities include, but are not limited to: Develop and maintain batch and streaming data pipelines according to business and technical requirements. Deliver observable, reliable and secure software, embracing “you build it you run it” mentality, and focus on automation. Continually work on improving the codebase and have active participation in all aspects of the team, including agile ceremonies. Take an active role in story definition, assisting business stakeholders with acceptance criteria. Work with Principal Engineers and Architects to share and contribute to the broader technical vision. Practice and champion best practices, striving towards excellence and raising the bar within the department. Operationalize data processing systems (DevOps) and system observability (SRE) Qualifications 1+ years relevant experience in Data Engineering Experience of near Real Time &amp; Batch Data Pipeline development in a similar Big Data Engineering role. Programming skills with an OOP language (e.g., Java, Python) Proficient with SQL Experience working in a cloud environment such as Google Cloud Platform or AWS Hands on programming experience of the following (or similar) technologies: Kubernetes, Docker Apache Beam, Apache Flink, Apache Spark Google BigQuery, Snowflake Google BigTable Google Pub/Sub, Kafka Apache Airflow Experience implementing observability around data pipelines using SRE best practices. Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metric providers ranging from advertising, web analytics, and consumer devices. Bachelors’ degree with a specialization in Computer Science, Engineering, Physics, other quantitative field or equivalent industry experience. Desired Characteristics Strong Test-Driven Development background, with understanding of levels of testing required to continuously deliver value to production. Experience with large-scale video assets Ability to work effectively across functions, disciplines, and levels Team-oriented and collaborative approach with a demonstrated aptitude, enthusiasm and willingness to learn new methods, tools, practices and skills Ability to recognize discordant views and take part in constructive dialogue to resolve them Pride and ownership in your work and confident representation of your team to other parts of Additional Information NBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable. If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations in the US by calling 1-818-777-4107 and in the UK by calling +44 2036185726."},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=88672d3d4886f54d", "page": 21, "job_title": "Senior Data Engineer - Contractor", "company_name": "OpenCredo", "job_location": "London", "job_type": null, "jobkey": "88672d3d4886f54d", "date_posted": "5 days ago", "jobDescription": " **Please note this is an inside IR35 contract for 3-6 months initially** OpenCredo (OC) is a UK based software development consultancy helping clients achieve more by leveraging modern technology and delivery approaches. We are a community of passionate technologists who thrive on delivering pragmatic solutions for our clients' most complex challenges. Curious, tenacious but always sensitive to our clients' context, we are not afraid to speak our minds to help steer our clients towards understanding and achieving their key goals. We are looking for a hands-on senior data engineer / architect who has worked with modern data technologies and operated with data at scale. You relish building modular configurable pipelines and solutions. You are well-versed in the challenges of working with streaming data, including handling windowing and aggregation challenges. You know the cases for streaming, ETL, ELT and batch processing, with experience bringing these approaches together in a coherent solution. Whilst we welcome broad experience across multiple clouds, you should have recent experience and be comfortable working with AWS data services and ecosystem (eg Kinesis, EMR, S3, Athena). This should include hands-on integration and development using core open source technologies such as Apache Kafka, Flink, Nifi, Spark and Airflow. What we’re looking for: A Data expert with great communication skills: You will be comfortable articulating and explaining key data concepts as well as diving into the details and the nitty-gritty where required. You are confident in your ability to deliver, upskill and transfer knowledge in your role as a technical Data Expert. You see value in, and make defining and documenting standard operating procedures (SOPs) and/or playbooks a part of helping ensure everyone is on the same page. Data Pipelines &amp; LifeCycle: You are comfortable designing and building scalable data pipelines, you know your ETL from your ELT and you have hands-on experience of all phases of the data lifecycle from ingestion, to cleansing, transforming as well as orchestrating the workflow. A Problem Solver with a Can Do Attitude: You can be relied on as the person who gets stuck in and makes things happen. Big Data Architectures: You have developed and worked with Big data architectures. You know what is required to support and run large-scale realtime and batch data processing workloads, including how to distribute load as appropriate. A Skilled Technologist: You have a background in programming and creating data-centric solutions using code. You are an accomplished programmer in one or more programming languages ideally in Java, Python or both. Requirements Real-time Streaming: Design &amp; Development of real-time data streaming solutions (including handling time series data) leveraging modern technologies and industry practises using technologies such as: Apache Kafka, Flink, Spark, Beam OpenSource &amp; AWS Data Solutions: Design &amp; Development of data pipelines and solutions within one or more cloud providers but with a focus on AWS, utilising a mixture of open source (for example via EMR) as well as vendor-specific data offerings. Data Modelling &amp; Engineering: A solid understanding of data modelling, including handling RDBMS, structured and unstructured data along with different storage formats such as CSV, Avro, Parquet etc. Data Governance &amp; MDM: Experience in challenges and solutions required to make legacy operational data available for onward analytical consumption. Practical applications for ensuring data quality and validation is built into different stages of data workflows allowing for good Master Data Management (MDM) including use of progressive data storage layers i.e bronze silver gold. Handling Data At Scale: understanding or experience of one or more of : data lakehouse, data warehouse, data lake. Orchestration &amp; Dataflow management solutions: Building and orchestrating pipelines and workflows using Apache Airflow, as well as automating the flow of data between systems using frameworks like Apache Nifi. Benefits Need more reasons? Here's a few more... Work with some of the most exciting new technologies Spark off co-workers who’ll challenge your thinking and help you to achieve your potential Deal openly and honestly with customers Work alongside senior leaders who understand and value passionate technologists; "},
{"url": "https://www.indeed.com/m/basecamp/viewjob?viewtype=embedded&jk=d2503aa446bcf987", "page": 21, "job_title": "Data Engineer 6 month FTC", "company_name": "The Telegraph", "job_location": "London SW1W", "job_type": "Full-time", "jobkey": "d2503aa446bcf987", "date_posted": "Today", "jobDescription": "About the Role : This is a fantastic opportunity to work in a technical capacity within a dynamic team which build and operate high-performance data systems across a range of technologies to drive predictive insights and analytics across all TMG publishing platforms. We are project and innovation driven using mainly the Google Cloud Platform stack, Python, DBT, Adobe, Business Objects and work hand in hand with data scientists to deliver pro-type data solutions at scale. To be successful in this role, you'll need to be comfortable building and adapting these technologies to deliver the right business outcome. You will need to work closely with the data science team, business stakeholders, developers and operations and in return, you will gain exposure to the full range of technologies in the modern data landscape. It offers fantastic scope for a talented individual with a strong interest in data to broaden their experience in a 6 month fixed term contract. Key Responsibilities : Build shippable software following engineering standards in place Build and maintain key engineering blocks that other teams can rely upon (such as APIs and Big Data implementations) Support the current stack and be able to extend it with new features Work on R&amp;D projects Work closely with TMG’s business intelligence users, operations and development teams on projects and CR’s, encouraging a data driven and pragmatic approach to tackling challenges and problems Be responsible for maintaining the company’s data assets at required high quality levels Follow the Agile methodologies implemented in the Engineering team Help to design and build solid, efficient, stable APIs. Help to maintain the high standard of the code Keep up to date with the latest technologies and methodologies to ensure TMG stays ahead of the game Ensure a globally robust and highly scalable approach to development to support our growing number of global users and services Essential Skills : Python development skills: Experience with Python data pipelines, ability to implement ETL processes in Python Experience with TDD Knowledge of technologies: Git, Docker, Jenkins, REST API Experience with Google Cloud Platform At least 2 years of experience in data or software development Knowledge of big data platforms SQL, scripting, relational, BI Ability to propose, design and implement a simple ETL solutions both in batch and real-time Great organisational skills and the ability to juggle multiple streams of work Desirable Skills : Storages;( BigQuery, MySQL, Elasticsearch) Technologies: Azkaban, Airflow, Talend Data modelling skills. Designing simple star schemas if required Experience of software delivery within a high web trac/high volume transactional online / digital / media environment Working experience within Agile methodology Ability to build data visualisations, dashboards Ability to translate business requirements into technical tasks Benefits: The nature of our industry means life at the Telegraph Media Group is fast-paced, demanding, and interesting. We also want it to be rewarding for everyone who works here. From dynamic working opportunities, medical cover, and parental leave (six months fully paid maternity leave and enhanced paternity/partner leave), to life assurance, and season ticket loans, you can choose from a range of flexible benefits, designed to support your lifestyle and help you achieve a healthy work-life balance. Training and development With support from your manager and colleagues, you’ll also have access to a variety of training and development opportunities through The Academy. Covering a range of personal and professional skills, our courses enable you to develop an enjoyable and rewarding career. Our commitment to inclusion At Telegraph Media Group, we foster a diverse and inclusive workplace and we are committed to building a team that reflects a wide variety of skills, perspectives and backgrounds. We believe in equality of opportunity and welcome candidates from all backgrounds, regardless of age, gender, ethnicity, disability, sexual orientation, gender identity, socioeconomic background, religion and/or belief. We are proud to be a Disability Confident Employer as part of the government’s Disability Confident Scheme. If you are disabled or have a long-term health condition and would like support in applying for any of our roles or if you require any reasonable adjustments in the recruitment process with us, please make us aware. To find out more about Diversity, Inclusion and Belonging at Telegraph Media Group, and for more information on our purpose, beliefs, and people values, please visit our website."}
]